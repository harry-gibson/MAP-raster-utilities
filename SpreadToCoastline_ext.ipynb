{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline / Limits data matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook assists with matching a raster grid to a pre-existing coastline or mask. It will clip the data back to the coastline, fill the data \"out\" to the coastline, or both.\n",
    "\n",
    "You can run in two steps, e.g. clipping to the outline of one dataset such as a coastline and then filling to the outline of another dataset such as a Pf limits mask.\n",
    "\n",
    "Note that any cells that are \"clipped\" are discarded. If their values need transferring elsewhere (i.e. to a pixel within the coastline), see PopulationReallocator.ipynb\n",
    "\n",
    "The input grids (coastline, extra mask if used, and data) must all have exactly the same resolution and alignment (i.e. cells must overlay one another precisely). This needs sorting out with ArcMap / gdal_edit first! \n",
    "\n",
    "However the grids don't need to have the same extent - e.g. the global coastline can be used with an Africa data raster. See the code for calculation of necessary offsets in this scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdal_array\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cython function from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if not already installed then build at the command line in the Cython_Raster_Funcs directory using \n",
    "#  python setup.py build_ext --inplace\n",
    "# OR\n",
    "# import pyximport\n",
    "# pyximport.install()\n",
    "\n",
    "from Cython_Raster_Funcs.CoastlineMatching import matchToCoastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from General_Raster_Funcs.TiffManagement import SaveLZWTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip one or more files, without any filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coastlineFile = r'G:\\Supporting\\CoastGlobal_5k.tif'\n",
    "coastlineFile = r'G:\\Supporting\\CoastGlobal.tiff'\n",
    "coastlineFile = r'G:\\Supporting\\CoastGlobal.MGExtent.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the files to process \n",
    "#inFilePattern = r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_*_adm_2.tif'\n",
    "#inFiles = glob.glob(inFilePattern)\n",
    "\n",
    "# or for one file only\n",
    "inFiles = [r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data (matching resolution)\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif\n",
      "Clipped 806417 data cells that were outside provided limits\n",
      "Filled 224204 total cells within limits from nearby data\n",
      "Failed to fill 0 total cells within limits due to no data cells in range\n"
     ]
    }
   ],
   "source": [
    "for inFileName in inFiles:\n",
    "    print inFileName\n",
    "\n",
    "    outDataFile = os.path.splitext(inFileName)[0] + \".MG_Matched.tif\"\n",
    "    outFailFile = os.path.splitext(inFileName)[0] + \".MG_Errors.tif\"\n",
    "    inDS = gdal.Open(inFileName)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection() \n",
    "    \n",
    "    dTypeIn = bData.DataType\n",
    "    incomingNPtype = gdal_array.GDALTypeCodeToNumericTypeCode(dTypeIn)\n",
    "    if not issubclass(incomingNPtype, np.integer):\n",
    "        print \"Raster must be of integer type!\"\n",
    "        assert false\n",
    "        \n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    # (or satisfy yourself that they're close, as sometimes the irrational \n",
    "    # number resolutions don't return equal)\n",
    "    #  assert gtIn[1] == gtLand[1]\n",
    "    # assert gtIn[5] == gtLand[5]\n",
    "    \n",
    "    # the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "    landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "    landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "    #print (landOffsetN, landOffsetW)\n",
    "    \n",
    "    # read the whole data file and upcast to long\n",
    "    inData = bData.ReadAsArray().astype(long)\n",
    "    inDS = None\n",
    "    \n",
    "    # read the relevant parts of the land file\n",
    "    inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "    \n",
    "    # Dataset-specific munging: \n",
    "    # some files have been created badly: they have one nodata value of e.g. -3.4e38, \n",
    "    # but ALSO contain pixels at -9999 which should be taken as nodata (probably some dumb\n",
    "    # R or IDL code which always writes nodata as -9999 regardless of what the file is set to)\n",
    "    # Replace those\n",
    "    if ndvIn != -9999:\n",
    "        inData[inData==-9999] = ndvIn\n",
    "    # Alternatively or also, set ALL nodata pixels to -9999 \n",
    "    # as a maxvalue +ve nodata value doesn't work reliably e.g. arcmap might \n",
    "    # report -1xxxIND for the stats\n",
    "    # It doesn't even work reliably here (it's to do with the precision of the tiff format, \n",
    "    # most likely), or sometimes the large negative values get read as -inf (which fails equality \n",
    "    # test with everything) \n",
    "    # So just set all values beyond a reasonable limit to be nodata\n",
    "    inData[abs(inData) > 10e7] = -9999\n",
    "    inData[inData == 0] = -9999\n",
    "    ndvIn = -9999\n",
    "    \n",
    "    # Clip and fill (the only change needed to only clip would be to choose it here)\n",
    "    errors = matchToCoastline(inData, inLand, _NDV=ndvIn, \n",
    "                              applyClip=1, applyFill=1, \n",
    "                              useNearestNPixels=1, # just use the nearest pixel\n",
    "                              searchPixelRadius=20) # so long as it's within 20 pixels radius\n",
    "    \n",
    "    # write the data\n",
    "    SaveLZWTiff(r[i].astype(incomingNPtype), ndvIn, gtIn, projIn, outDir, outDataFile)\n",
    "    \n",
    "    # write the failures grid (no nodata)\n",
    "    SaveLZWTiff(np.asarray(errors), None, gtIn, projIn, outDir, outFailFile)\n",
    "#landDS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced use - match to a limits surface and a coastline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we wanted to ensure that we have data within the entirety of the Pf limits surface (stable or unstable) but none in the sea. \n",
    "\n",
    "However we don't want data on _all_ land, so we run as a two-stage process: first we spread to the limits layer, to ensure that is fully covered, then separately clip to the coastline.\n",
    "\n",
    "(Alternatively we could clip the limits layer to the coastline, then use that for a clip-and-fill on the data).\n",
    "\n",
    "This workflow assumes that the limits has at least as large an extent as the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The coastal data should be global and the limits (fill-to) mask should be at least as large as the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the data locations\n",
    "inDir = r'C:\\Temp\\PV_Alignment'\n",
    "inFN = 'PvPR_Aug2015_2_Clip1_Copy.tif'\n",
    "inLimsFN = 'PvPR_2010_5k.flt' # 'pvlims5f_5k.tif'\n",
    "\n",
    "outFN = 'PvPR_Aug2015_2_Clip1_Copy_FilledToPvPRLims.tif'\n",
    "outFailFN = 'PvPR_Aug2015_2_Clip1_Copy_PvPRLimsFillFailures.tif'\n",
    "\n",
    "inFile = os.path.join(inDir, inFN)\n",
    "inLimsFile = os.path.join(inDir, inLimsFN)\n",
    "\n",
    "outDataFile = os.path.join(inDir, outFN)\n",
    "outFailFile = os.path.join(inDir, outFailFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the whole extent of the data\n",
    "inDS = gdal.Open(inFile)\n",
    "bData = inDS.GetRasterBand(1)\n",
    "ndvIn = bData.GetNoDataValue()\n",
    "gtIn = inDS.GetGeoTransform()\n",
    "projIn = inDS.GetProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure the resolutions match (not actually checking the alignment)\n",
    "assert gtIn[1] == gtLand[1]\n",
    "assert gtIn[5] == gtLand[5]\n",
    "\n",
    "assert gtIn[1] == gtLims[1]\n",
    "assert gtIn[5] == gtLims[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work out which bits of the mask files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN, landOffsetW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the maybe-global clipping image?\n",
    "maskOffsetW = int((gtIn[0]-gtLims[0]) / gtLims[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "maskOffsetN = int((gtIn[3]-gtLims[3]) / gtLims[5])\n",
    "maskOffsetN, maskOffsetW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all the data file\n",
    "inData = bData.ReadAsArray(dataOffsetW, dataOffsetN, dataReadXSize, dataReadYSize).astype(long)\n",
    "# read the relevant parts of the land and mask files\n",
    "inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "inMask = bLims.ReadAsArray(maskOffsetW, maskOffsetN, inData.shape[1], inData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the limits data (specific to this dataset) - reclass the pv limits values into a 0-1 mask for data / nodata\n",
    "# NB keeping \"0\" as \"data\"\n",
    "#inMask[inMask!=3] = 10\n",
    "#inMask[inMask==3] = 0\n",
    "#inMask[inMask==10] = 1\n",
    "inMask[inMask != ndvMask] = 1\n",
    "inMask[inMask == ndvMask] = 0\n",
    "inMask = inMask.astype(np.byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the fill and clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the spreading to generate values for all pixels of the limits surface\n",
    "# but do not clip to it, because the new Pv data covers more areas (e.g. algeria)\n",
    "# than the limits - we don't want to delete that data.\n",
    "fillErrors = matchToCoastline(inData, inMask, _NDV=ndvIn, \n",
    "                              applyClip=0, \n",
    "                              applyFill=1\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now clip the data to the coastline, but do not fill (as we don't want to fill into all land)\n",
    "clipErrors = matchToCoastline(inData, inLand, _NDV=ndvIn, \n",
    "                              applyClip=1, \n",
    "                              applyFill=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the data\n",
    "SaveLZWTiff(inData, ndvIn, gtIn, projIn, inDir, outFN)\n",
    "\n",
    "# write the failures grid (no nodata)\n",
    "SaveLZWTiff(np.asarray(errors), None, gtIn, projIn, inDir, outFailFN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage 2 - match multiple files of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have multiple input / data files that must be matched to a single limits layer. We want data in the cells of the limits layer and *only* those cells, i.e. we want to both fill to and clip to the limits layer.\n",
    "\n",
    "(The limits layer was in fact created by clipping to the coastline using the first workflow above, so we are then effectively clipping to the coastline at the same time).\n",
    "\n",
    "The limits layer is not global, and some of the data file may cover a larger extent than the limits: so we need to read the limits into the appropriate part of an array of the same size as the data file each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inFilePattern = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\*.tif'\n",
    "inFiles = glob.glob(inFilePattern)\n",
    "outDir = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the ITN file will be used as our limits layer \n",
    "inFiles.index(r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\2015.ITN.use.yearavg.adj.stable.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limsFile = inFiles.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()\n",
    "\n",
    "for inFile in inFiles:\n",
    "    # Read the whole extent of the data each time\n",
    "    print \"__________________________________________\"\n",
    "    print inFile\n",
    "    inDS = gdal.Open(inFile)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection()\n",
    "\n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    assert gtIn[1] == gtLims[1]\n",
    "    assert gtIn[5] == gtLims[5]\n",
    "    # read all the data file\n",
    "    inData = bData.ReadAsArray().astype(np.float32)\n",
    "    inDataOrig = bData.ReadAsArray()\n",
    "    \n",
    "    # Create an array for the limits that is the same size as the data, then read the appropriate \n",
    "    # part of the limits into the appropriate part of this array\n",
    "    inMask = np.empty(shape=inData.shape)\n",
    "    inMask[:] = ndvMask\n",
    "    \n",
    "    # how many pixels from the W edge of the limits does the W edge of the data sit?\n",
    "    # This will be negative if the data goes further west than the limits\n",
    "    maskOffsetW = int((gtIn[0] - gtLims[0]) / gtLims[1])\n",
    "    # how many pixels from the N edge of the limits does the N edge of the data sit?\n",
    "    # This will be negative if the data goes further north than the limits\n",
    "    maskOffsetN = int((gtIn[3] - gtLims[3]) / gtLims[5])\n",
    "    print \"Mask offsets are \"+str((maskOffsetN, maskOffsetW))\n",
    "    \n",
    "    # find the top left corner (in the data) of the limits we can read\n",
    "    if maskOffsetN < 0:\n",
    "        maskInDataOffsetN = abs(maskOffsetN) + 1\n",
    "        maskOffsetN = 0\n",
    "    else:\n",
    "        maskInDataOffsetN = 0\n",
    "    \n",
    "    if maskOffsetW < 0:\n",
    "        maskInDataOffsetW = abs(maskOffsetW) + 1\n",
    "        maskOffsetW = 0\n",
    "    else:\n",
    "        maskInDataOffsetW = 0\n",
    "    \n",
    "    dataYSize, dataXSize = inData.shape\n",
    "    maskYSize = limsDS.RasterYSize\n",
    "    maskXSize = limsDS.RasterXSize\n",
    "    \n",
    "    # find how large the limits array we can read is\n",
    "    if maskOffsetW + dataXSize > maskXSize:\n",
    "        # the data goes beyond the E edge of the mask; read to the mask's edge\n",
    "        maskReadXSize = maskXSize - maskOffsetW\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadXSize = dataXSize\n",
    "    if maskOffsetN + dataYSize > maskYSize:\n",
    "        # the data goes beyond the S edge of the mask; read to the mask's edge\n",
    "        maskReadYSize = maskYSize - maskOffsetN\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadYSize = dataYSize\n",
    "        \n",
    "    if (maskInDataOffsetN > 0 or maskInDataOffsetW > 0):\n",
    "        print inFile + \" has greater extent than limits, reading mask as offset!\"\n",
    "    \n",
    "    # read the relevant part of the mask file into the relevant part of the pre-prepared \n",
    "    # mask array (leaving any other part as nodata)\n",
    "    inMask[maskInDataOffsetN:maskInDataOffsetN + maskReadYSize,\n",
    "           maskInDataOffsetW:maskInDataOffsetW + maskReadXSize] = bLims.ReadAsArray(\n",
    "    maskOffsetW, maskOffsetN, maskReadXSize, maskReadYSize)\n",
    "    \n",
    "    # specific task for this mask image: the mask image wasn't actually a mask; \n",
    "    # we just want to use anywhere that it wasn't nodata as our mask, so reclass it\n",
    "    inMask[inMask != ndvMask] = 1\n",
    "    inMask[inMask == ndvMask] = 0\n",
    "    inMask = inMask.astype(np.byte)\n",
    "    \n",
    "    # Specific task for these data images: \n",
    "    # We have been asked to set all locations within the limits, where the data image \n",
    "    # is nodata, to zero, rather than filling based on nearest neighbours.\n",
    "    # Also some images have nodata as -inf which doesn't play nicely with equality test,\n",
    "    # so look for anything with an enormous negative value.\n",
    "    inData[np.logical_and(np.logical_or(inData==ndvIn, inData<-1e100),\n",
    "                          inMask == 1)] = 0\n",
    "    \n",
    "    # Spread and clip to the mask dataset only (the fill should not result in any \n",
    "    # cells being filled, due to the above step: we could turn it off)\n",
    "    errors = spreadToCoast(inData, inMask, _NDV=ndvIn, applyClip=1, applyFill=1)\n",
    "    \n",
    "    outDataFile = inFile.replace(\".tif\", \".MG_Matched.LimsClipped.tif\")\n",
    "    # write the data - the geotransform is unchanged as we worked with the data extent\n",
    "    # not the mask extent\n",
    "    writeTiffFile(inData, outDataFile, gtIn, projIn, ndvIn, gdal.GDT_Float32 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
