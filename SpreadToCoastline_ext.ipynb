{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline / Limits data matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook assists with matching a raster grid to a pre-existing coastline or mask. It will clip the data back to the coastline, fill the data \"out\" to the coastline, or both. \n",
    "\n",
    "The filling part of the process is akin to the ArcGIS operation called \"Nibble\": cells that are no-data, but which are flagged by a separate mask grid to indicate that they ought to have data, are given a value taken from the nearest cell which has data. This code can optionally take that value from a single nearby cell, or from an average of several.\n",
    "\n",
    "You can run in two steps, e.g. clipping to the outline of one dataset such as a coastline and then filling to the outline of another dataset such as a Pf limits mask.\n",
    "\n",
    "Note that any cells that are \"clipped\" are discarded. If their values need transferring elsewhere (i.e. to a pixel within the coastline), see the notebook **PopulationReallocator**\n",
    "\n",
    "The input grids (coastline, extra mask if used, and data) must all have exactly the same resolution and alignment (i.e. cells must overlay one another precisely). This needs sorting out with ArcMap / gdal_edit first! \n",
    "\n",
    "However the grids don't need to have the same extent - e.g. the global coastline can be used with an Africa data raster. See the code for calculation of necessary offsets in this scenario.\n",
    "\n",
    "The input data must be of integer type - this is intended for filling of categorical data. For clipping of floating point data the code in the **PopulationReallocator** notebook can be used instead, with the reallocation function turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdal_array\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cython function from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name matchToCoastline",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-af8a45a34193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# import pyximport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# pyximport.install()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mraster_utilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemplate_matching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatchToCoastline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatchToCoastline_Float\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name matchToCoastline"
     ]
    }
   ],
   "source": [
    "# if not already installed then build at the command line in the Cython_Raster_Funcs directory using \n",
    "#  python setup.py build_ext --inplace\n",
    "# OR\n",
    "# import pyximport\n",
    "# pyximport.install()\n",
    "from raster_utilities.template_matching import matchToCoastline, matchToCoastline_Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from raster_utilities.io.tiff_management import SaveLZWTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip one or more files, with or without also filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coastlineFile = r'G:\\Supporting\\CoastGlobal_5k.tif'\n",
    "#coastlineFile = r'\\\\map-fs1.ndph.ox.ac.uk\\map_data\\mastergrids\\Global_Masks\\Land_Sea_Masks\\CoastGlobal.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the files to process \n",
    "#inFilePattern = r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_*_adm_2.tif'\n",
    "#inFiles = glob.glob(inFilePattern)\n",
    "inFiles = glob.glob(r'\\\\map-fs1.ndph.ox.ac.uk\\map_data\\Madagascar_PfPR\\Covariate_data\\Monthly_variables\\TSI_New\\*.tif')\n",
    "\n",
    "# or for one file only\n",
    "#inFiles = [r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif']\n",
    "#inFiles = [r'C:\\Temp\\testagg\\mos\\Global_Urban_Footprint_5km_UrbanLikeAdjacency_unmatched.tif']\n",
    "#inFiles = [r'C:\\Temp\\dataprep\\ihme_2016\\GBD2016_analysis_polygons_with_pop_level_priority.tif']\n",
    "\n",
    "# set the output folder\n",
    "outDir = r'C:\\Temp\\dataprep\\ihme_2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data (matching resolution)\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the fill parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify whether we should clip and / or fill, (either or both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applyClip = 1\n",
    "applyFill = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the useNearestNValues variable to 1 to use the nearest cell value, like Nibble. Set to a number greater than 1 to use the average of several nearby data cells. (Not relevant if applyFill == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useNearestNValues = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either case the fill-source pixel(s) must be found within a radius of this many pixels, otherwise no fill value will be found and the error flag will be set at the location in question. Setting this too high will cause the processing to be slower. (Not relevant if applyFill==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchPixelRadius = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for inFileName in inFiles:\n",
    "    print inFileName\n",
    "\n",
    "    outDataFile = os.path.splitext(inFileName)[0] + \".MG_Clipped.tif\"\n",
    "    outFailFile = os.path.splitext(inFileName)[0] + \".MG_Clip_Errors.tif\"\n",
    "    inDS = gdal.Open(inFileName)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    if ndvIn:\n",
    "        print \"Nodata incoming is \"+str(ndvIn)\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection() \n",
    "    \n",
    "    dTypeIn = bData.DataType\n",
    "    incomingNPtype = gdal_array.GDALTypeCodeToNumericTypeCode(dTypeIn)\n",
    "    fillType = None\n",
    "    if issubclass(incomingNPtype, np.integer):\n",
    "        fillType = \"int\"\n",
    "    elif issubclass(incomingNPtype, np.float32):\n",
    "        fillType = \"float\"\n",
    "    else:\n",
    "        print \"Raster must be of integer or float type!\"\n",
    "        assert False\n",
    "        \n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    # (or satisfy yourself that they're close, as sometimes the irrational \n",
    "    # number resolutions don't return equal)\n",
    "    #  assert gtIn[1] == gtLand[1]\n",
    "    # assert gtIn[5] == gtLand[5]\n",
    "    \n",
    "    # the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "    landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "    landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "    #print (landOffsetN, landOffsetW)\n",
    "    \n",
    "    # read the whole data file and upcast to long\n",
    "    inData = bData.ReadAsArray()\n",
    "    if fillType == \"int\":\n",
    "        inData = inData.astype(long)\n",
    "    else:\n",
    "        inData = inData.astype(np.float32)\n",
    "    inDS = None\n",
    "    \n",
    "    # read the relevant parts of the land file\n",
    "    inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "    \n",
    "    # Dataset-specific munging: \n",
    "    # some files have been created badly: they have one nodata value of e.g. -3.4e38, \n",
    "    # but ALSO contain pixels at -9999 which should be taken as nodata (probably some dumb\n",
    "    # R or IDL code which always writes nodata as -9999 regardless of what the file is set to)\n",
    "    # Replace those\n",
    "    if ndvIn != -9999:\n",
    "        if ((inData==-9999).any()):\n",
    "            print \"Image contains -9999 but this isn't recorded as nodata: recording it as such\"\n",
    "            inData[inData==-9999] = ndvIn\n",
    "    \n",
    "    # Alternatively or also, set ALL nodata pixels to -9999 \n",
    "    # as a maxvalue +ve nodata value doesn't work reliably e.g. arcmap might \n",
    "    # report -1xxxIND for the stats\n",
    "    # It doesn't even work reliably here (it's to do with the precision of the tiff format, \n",
    "    # most likely), or sometimes the large negative values get read as -inf (which fails equality \n",
    "    # test with everything) \n",
    "    # So just set all values beyond a reasonable limit to be nodata\n",
    "    if abs(inData.max())>10e7:\n",
    "        print \"Image appears to have maxvalue as nodata - resetting to -9999\"\n",
    "        inData[abs(inData) > 10e7] = -9999\n",
    "        ndvIn = -9999\n",
    "    \n",
    "    if fillType == \"int\":\n",
    "        # Clip and / or fill (according to the options chosen above)\n",
    "        errors = matchToCoastline(inData, inLand, _NDV=ndvIn, \n",
    "                                  applyClip=applyClip, applyFill=applyFill, \n",
    "                                  useNearestNPixels=useNearestNValues, \n",
    "                                  searchPixelRadius=searchPixelRadius) # so long as it's within 20 pixels radius\n",
    "    else:\n",
    "        errors = matchToCoastline_Float(inData, inLand, _NDV=ndvIn,\n",
    "                                        applyClip = applyClip, applyFill = applyFill,\n",
    "                                        useNearestNPixels=useNearestNValues,\n",
    "                                        searchPixelRadius=searchPixelRadius)\n",
    "    # write the data (the inData array was modified in-place)\n",
    "    SaveLZWTiff(inData.astype(incomingNPtype), ndvIn, gtIn, projIn, outDir, outDataFile)\n",
    "    \n",
    "    # write the failures grid (no nodata)\n",
    "    SaveLZWTiff(np.asarray(errors), None, gtIn, projIn, outDir, outFailFile)\n",
    "#landDS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced use - match separately to a limits surface and a coastline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we wanted to ensure that we have data within the entirety of the Pf limits surface (stable or unstable) but none in the sea. \n",
    "\n",
    "However we don't want data on _all_ land, so we run as a two-stage process: first we spread to the limits layer, to ensure that is fully covered, then separately clip to the coastline.\n",
    "\n",
    "(Alternatively we could clip the limits layer to the coastline, then use that for a clip-and-fill on the data).\n",
    "\n",
    "This workflow assumes that the limits has at least as large an extent as the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The coastal data should be global and the limits (fill-to) mask should be at least as large as the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the data locations\n",
    "inDir = r'C:\\Temp\\PV_Alignment'\n",
    "inFN = 'PvPR_Aug2015_2_Clip1_Copy.tif'\n",
    "inLimsFN = 'PvPR_2010_5k.flt' # 'pvlims5f_5k.tif'\n",
    "\n",
    "outFN = 'PvPR_Aug2015_2_Clip1_Copy_FilledToPvPRLims.tif'\n",
    "outFailFN = 'PvPR_Aug2015_2_Clip1_Copy_PvPRLimsFillFailures.tif'\n",
    "\n",
    "inFile = os.path.join(inDir, inFN)\n",
    "inLimsFile = os.path.join(inDir, inLimsFN)\n",
    "\n",
    "outDataFile = os.path.join(inDir, outFN)\n",
    "outFailFile = os.path.join(inDir, outFailFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the whole extent of the data\n",
    "inDS = gdal.Open(inFile)\n",
    "bData = inDS.GetRasterBand(1)\n",
    "ndvIn = bData.GetNoDataValue()\n",
    "gtIn = inDS.GetGeoTransform()\n",
    "projIn = inDS.GetProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure the resolutions match (not actually checking the alignment)\n",
    "assert gtIn[1] == gtLand[1]\n",
    "assert gtIn[5] == gtLand[5]\n",
    "\n",
    "assert gtIn[1] == gtLims[1]\n",
    "assert gtIn[5] == gtLims[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work out which bits of the mask files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN, landOffsetW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the maybe-global clipping image?\n",
    "maskOffsetW = int((gtIn[0]-gtLims[0]) / gtLims[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "maskOffsetN = int((gtIn[3]-gtLims[3]) / gtLims[5])\n",
    "maskOffsetN, maskOffsetW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all the data file\n",
    "inData = bData.ReadAsArray(dataOffsetW, dataOffsetN, dataReadXSize, dataReadYSize).astype(long)\n",
    "# read the relevant parts of the land and mask files\n",
    "inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "inMask = bLims.ReadAsArray(maskOffsetW, maskOffsetN, inData.shape[1], inData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the limits data (specific to this dataset) - reclass the pv limits values into a 0-1 mask for data / nodata\n",
    "# NB keeping \"0\" as \"data\"\n",
    "#inMask[inMask!=3] = 10\n",
    "#inMask[inMask==3] = 0\n",
    "#inMask[inMask==10] = 1\n",
    "inMask[inMask != ndvMask] = 1\n",
    "inMask[inMask == ndvMask] = 0\n",
    "inMask = inMask.astype(np.byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the fill and clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the spreading to generate values for all pixels of the limits surface\n",
    "# but do not clip to it, because the new Pv data covers more areas (e.g. algeria)\n",
    "# than the limits - we don't want to delete that data.\n",
    "fillErrors = matchToCoastline(inData, inMask, _NDV=ndvIn, \n",
    "                              applyClip=0, \n",
    "                              applyFill=1\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now clip the data to the coastline, but do not fill (as we don't want to fill into all land)\n",
    "clipErrors = matchToCoastline(inData, inLand, _NDV=ndvIn, \n",
    "                              applyClip=1, \n",
    "                              applyFill=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the data\n",
    "SaveLZWTiff(inData, ndvIn, gtIn, projIn, inDir, outFN)\n",
    "\n",
    "# write the failures grid (no nodata)\n",
    "SaveLZWTiff(np.asarray(errors), None, gtIn, projIn, inDir, outFailFN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage 2 - match multiple files of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have multiple input / data files that must be matched to a single limits layer. We want data in the cells of the limits layer and *only* those cells, i.e. we want to both fill to and clip to the limits layer.\n",
    "\n",
    "(The limits layer was in fact created by clipping to the coastline using the first workflow above, so we are then effectively clipping to the coastline at the same time).\n",
    "\n",
    "The limits layer is not global, and some of the data file may cover a larger extent than the limits: so we need to read the limits into the appropriate part of an array of the same size as the data file each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inFilePattern = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\*.tif'\n",
    "inFiles = glob.glob(inFilePattern)\n",
    "outDir = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the ITN file will be used as our limits layer \n",
    "inFiles.index(r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\2015.ITN.use.yearavg.adj.stable.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limsFile = inFiles.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()\n",
    "\n",
    "for inFile in inFiles:\n",
    "    # Read the whole extent of the data each time\n",
    "    print \"__________________________________________\"\n",
    "    print inFile\n",
    "    inDS = gdal.Open(inFile)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection()\n",
    "\n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    assert gtIn[1] == gtLims[1]\n",
    "    assert gtIn[5] == gtLims[5]\n",
    "    # read all the data file\n",
    "    inData = bData.ReadAsArray().astype(np.float32)\n",
    "    inDataOrig = bData.ReadAsArray()\n",
    "    \n",
    "    # Create an array for the limits that is the same size as the data, then read the appropriate \n",
    "    # part of the limits into the appropriate part of this array\n",
    "    inMask = np.empty(shape=inData.shape)\n",
    "    inMask[:] = ndvMask\n",
    "    \n",
    "    # how many pixels from the W edge of the limits does the W edge of the data sit?\n",
    "    # This will be negative if the data goes further west than the limits\n",
    "    maskOffsetW = int((gtIn[0] - gtLims[0]) / gtLims[1])\n",
    "    # how many pixels from the N edge of the limits does the N edge of the data sit?\n",
    "    # This will be negative if the data goes further north than the limits\n",
    "    maskOffsetN = int((gtIn[3] - gtLims[3]) / gtLims[5])\n",
    "    print \"Mask offsets are \"+str((maskOffsetN, maskOffsetW))\n",
    "    \n",
    "    # find the top left corner (in the data) of the limits we can read\n",
    "    if maskOffsetN < 0:\n",
    "        maskInDataOffsetN = abs(maskOffsetN) + 1\n",
    "        maskOffsetN = 0\n",
    "    else:\n",
    "        maskInDataOffsetN = 0\n",
    "    \n",
    "    if maskOffsetW < 0:\n",
    "        maskInDataOffsetW = abs(maskOffsetW) + 1\n",
    "        maskOffsetW = 0\n",
    "    else:\n",
    "        maskInDataOffsetW = 0\n",
    "    \n",
    "    dataYSize, dataXSize = inData.shape\n",
    "    maskYSize = limsDS.RasterYSize\n",
    "    maskXSize = limsDS.RasterXSize\n",
    "    \n",
    "    # find how large the limits array we can read is\n",
    "    if maskOffsetW + dataXSize > maskXSize:\n",
    "        # the data goes beyond the E edge of the mask; read to the mask's edge\n",
    "        maskReadXSize = maskXSize - maskOffsetW\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadXSize = dataXSize\n",
    "    if maskOffsetN + dataYSize > maskYSize:\n",
    "        # the data goes beyond the S edge of the mask; read to the mask's edge\n",
    "        maskReadYSize = maskYSize - maskOffsetN\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadYSize = dataYSize\n",
    "        \n",
    "    if (maskInDataOffsetN > 0 or maskInDataOffsetW > 0):\n",
    "        print inFile + \" has greater extent than limits, reading mask as offset!\"\n",
    "    \n",
    "    # read the relevant part of the mask file into the relevant part of the pre-prepared \n",
    "    # mask array (leaving any other part as nodata)\n",
    "    inMask[maskInDataOffsetN:maskInDataOffsetN + maskReadYSize,\n",
    "           maskInDataOffsetW:maskInDataOffsetW + maskReadXSize] = bLims.ReadAsArray(\n",
    "    maskOffsetW, maskOffsetN, maskReadXSize, maskReadYSize)\n",
    "    \n",
    "    # specific task for this mask image: the mask image wasn't actually a mask; \n",
    "    # we just want to use anywhere that it wasn't nodata as our mask, so reclass it\n",
    "    inMask[inMask != ndvMask] = 1\n",
    "    inMask[inMask == ndvMask] = 0\n",
    "    inMask = inMask.astype(np.byte)\n",
    "    \n",
    "    # Specific task for these data images: \n",
    "    # We have been asked to set all locations within the limits, where the data image \n",
    "    # is nodata, to zero, rather than filling based on nearest neighbours.\n",
    "    # Also some images have nodata as -inf which doesn't play nicely with equality test,\n",
    "    # so look for anything with an enormous negative value.\n",
    "    inData[np.logical_and(np.logical_or(inData==ndvIn, inData<-1e100),\n",
    "                          inMask == 1)] = 0\n",
    "    \n",
    "    # Spread and clip to the mask dataset only (the fill should not result in any \n",
    "    # cells being filled, due to the above step: we could turn it off)\n",
    "    errors = spreadToCoast(inData, inMask, _NDV=ndvIn, applyClip=1, applyFill=1)\n",
    "    \n",
    "    outDataFile = inFile.replace(\".tif\", \".MG_Matched.LimsClipped.tif\")\n",
    "    # write the data - the geotransform is unchanged as we worked with the data extent\n",
    "    # not the mask extent\n",
    "    writeTiffFile(inData, outDataFile, gtIn, projIn, ndvIn, gdal.GDT_Float32 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
