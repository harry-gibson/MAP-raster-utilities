{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastline / Limits data matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook assists with matching a raster grid to a pre-existing coastline or mask. It will clip the data back to the coastline, fill the data \"out\" to the coastline, or both.\n",
    "\n",
    "You can run in two steps, e.g. clipping to the outline of one dataset such as a coastline and then filling to the outline of another dataset such as a Pf limits mask.\n",
    "\n",
    "Note that any cells that are \"clipped\" are discarded. If their values need transferring elsewhere (i.e. to a pixel within the coastline), see PopulationReallocator.ipynb\n",
    "\n",
    "The input grids (coastline, extra mask if used, and data) must all have exactly the same resolution and alignment (i.e. cells must overlay one another precisely). This needs sorting out with ArcMap / gdal_edit first! \n",
    "\n",
    "However the grids don't need to have the same extent - e.g. the global coastline can be used with an Africa data raster. See the code for calculation of necessary offsets in this scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coastlineFile = r'G:\\Supporting\\CoastGlobal_5k.tif'\n",
    "coastlineFile = r'G:\\Supporting\\CoastGlobal.tiff'\n",
    "coastlineFile = r'G:\\Supporting\\CoastGlobal.MGExtent.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Cython function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=/openmp --link-args=/openmp --force \n",
    "# openmp not actually used in this implementation, can drop the above\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport openmp\n",
    "from cython.parallel import parallel, prange\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "\n",
    "cpdef spreadToCoast(long long[:,::1] data, char[:,::1] lsMask, long long _NDV=-9999,\n",
    "                           char applyClip=1, char applyFill=1, int nearestNPixels=10, \n",
    "                           int searchRadius=1000, int noLosses=0):\n",
    "    ''' \n",
    "    Matches a data image to a mask image by removing / adding pixels from the data.\n",
    "    \n",
    "    Fills in gaps around a coastline or other limits layer to create an output dataset \n",
    "    that is flush to the coast, and clips (removes) data outside of the coast. Both filling \n",
    "    and clipping are optional - i.e. either or both can be done.\n",
    "    \n",
    "    Clipping, if done, is done before filling so the values removed do not participate in calculating\n",
    "    a fill value for missing inland pixels.\n",
    "    \n",
    "    The mask should have value 1 for areas that should have data, and 0 for areas that should \n",
    "    have nodata.\n",
    "    \n",
    "    Gaps are filled with the mean of up to the nearest 10 data-containing pixels, or as specified.\n",
    "    (Fewer are used if fewer are found: a fill is created if at least one is found.)\n",
    "    The fill process is iterative i.e. fill values for one pixel can then be used in generating \n",
    "    a fill for adjacent pixels. This will lead to \"smearing\" and so this algorithm isn't appropriate\n",
    "    for filling large areas.\n",
    "    \n",
    "    For use when an input dataset has been created with a different coastline and now we require\n",
    "    a dataset that matches MAP's One True Coastline (TM). \n",
    "    \n",
    "    See also reallocateToUnmasked which has a similar, but somewhat different purpose, for population\n",
    "    data where totals must be maintained. This version doesn't maintain totals.\n",
    "    '''\n",
    "    \n",
    "    cdef:\n",
    "        Py_ssize_t xShapeIn, yShapeIn #, xShapeOut, yShapeOut\n",
    "        Py_ssize_t xIn, yIn, xNbr, yNbr, nbrIndex_prv\n",
    "        float localValue\n",
    "        int[:,::1] nbrIntCoords\n",
    "        char[:,::1] failedLocs\n",
    "        int filledCells, failedFills, clippedCells\n",
    "       # float failedReallocationPop,  reallocatedTotalPop\n",
    "        char reallocatedOK\n",
    "        int _MAX_NEIGHBOURS_TO_CHECK = 1000\n",
    "        int reallocationSum_prv\n",
    "        int reallocationCount_prv\n",
    "    yShapeIn = data.shape[0]\n",
    "    xShapeIn = data.shape[1]\n",
    "    assert lsMask.shape[0] == yShapeIn\n",
    "    assert lsMask.shape[1] == xShapeIn\n",
    "    \n",
    "     # Generate the neighbour spiral search table out to \"a bit\" further than needed\n",
    "    _SEARCH_RADIUS = searchRadius # <int> ((sqrt(_MAX_NEIGHBOURS_TO_CHECK / 3.14)) + 5)\n",
    "    diam = _SEARCH_RADIUS * 2 + 1\n",
    "    inds = np.indices([diam,diam]) - _SEARCH_RADIUS\n",
    "    distTmp = np.sqrt((inds ** 2).sum(0))\n",
    "    npTmpTable = ((inds.T).reshape(diam**2, 2))\n",
    "    npTmpTable = np.append(npTmpTable, distTmp.ravel()[:,None],axis=1)\n",
    "    # sort the table by distance then x then y (the arguments are last-sort-first)\n",
    "    order = np.lexsort((npTmpTable[:,1],npTmpTable[:,0],npTmpTable[:,2]))\n",
    "    npTmpTable = np.take(npTmpTable,order,axis=0)\n",
    "    # transfer to a C-side object transposed to have three rows and many columns and in \n",
    "    # C-contiguous layout, so that cython can access individual nbr coord sets more quickly\n",
    "    nbrTable = np.copy((npTmpTable[npTmpTable[:,2] <= _SEARCH_RADIUS]).T,order='c')\n",
    "    # cast the columns that will be used as array indices to int type once here, rather \n",
    "    # than casting repeatedly inside the inner loop\n",
    "    nbrIntCoords = np.asarray(nbrTable[0:2,:]).astype(np.int32)\n",
    "    \n",
    "    filledCells = 0\n",
    "    failedFills = 0\n",
    "    clippedCells = 0\n",
    "    \n",
    "    failedLocs = np.zeros_like(lsMask)\n",
    "    \n",
    "    if applyClip:\n",
    "        for yIn in range (yShapeIn):\n",
    "            for xIn in range (xShapeIn):\n",
    "                if lsMask[yIn, xIn] == 0:\n",
    "                    if data[yIn, xIn] != _NDV:\n",
    "                        clippedCells += 1\n",
    "                        data[yIn, xIn] = _NDV\n",
    "    \n",
    "    if applyFill:\n",
    "        for yIn in range(yShapeIn):\n",
    "            for xIn in range(xShapeIn):\n",
    "                if lsMask[yIn, xIn] == 0 or data[yIn,xIn] != _NDV:\n",
    "                    # there is nothing to do as we are in sea or the data are good\n",
    "                    continue\n",
    "                # otherwise we are on land but nodata. Find nearest data to reallocate it\n",
    "                reallocatedOK = 0\n",
    "                reallocationCount_prv = 0\n",
    "                reallocationSum_prv = 0\n",
    "                for nbrIndex_prv in range(1, _MAX_NEIGHBOURS_TO_CHECK):\n",
    "                    if reallocationCount_prv == nearestNPixels:\n",
    "                        break\n",
    "                    # use int-type coords array to avoid cast op in tight loop\n",
    "                    xNbr = xIn + nbrIntCoords[0, nbrIndex_prv]\n",
    "                    yNbr = yIn + nbrIntCoords[1, nbrIndex_prv]\n",
    "                    if (xNbr >= 0 and xNbr < xShapeIn and \n",
    "                        yNbr >= 0 and yNbr < yShapeIn and\n",
    "                        data[yNbr, xNbr] != _NDV):\n",
    "                        # NB we allow a sea pixel with data to supply a fill value\n",
    "                        # unless they have been clipped out previously\n",
    "                        reallocationSum_prv += data[yNbr, xNbr]\n",
    "                        reallocationCount_prv += 1\n",
    "                if reallocationCount_prv > 0:\n",
    "                    # we modify the input. So, this fill value may be found and used \n",
    "                    # when looking for neighbours for adjacent pixels. This will lead \n",
    "                    # to \"smearing\" of values in an easterly and southerly direction.\n",
    "                    # Hence, not suitable for filling large areas!\n",
    "                    data[yIn, xIn] = reallocationSum_prv#  / reallocationCount_prv\n",
    "                    filledCells += 1\n",
    "                else:\n",
    "                    failedFills += 1\n",
    "                    failedLocs[yIn, xIn] = 1\n",
    "\n",
    "    print (\"Clipped {0!s} data cells that were outside provided limits\".format(\n",
    "        clippedCells))\n",
    "    print (\"Filled {0!s} total cells within limits from nearby data\".format(\n",
    "        filledCells))\n",
    "    print (\"Failed to fill {0!s} total cells within limits due to no data cells in range\".format(\n",
    "        failedFills))\n",
    "    return failedLocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeTiffFile(dataArray, fileName, geoTransform, projection, \n",
    "                 noDataValue=None, dataType=gdal.GDT_Float32):\n",
    "    ''' Saves array to a single band geotiff file with our normal compression settings '''\n",
    "    outDrv = gdal.GetDriverByName(\"GTiff\")\n",
    "    outRaster = outDrv.Create(fileName, dataArray.shape[1], dataArray.shape[0], 1,\n",
    "                              dataType,\n",
    "                              [\"COMPRESS=LZW\", \"TILED=YES\", \"SPARSE_OK=TRUE\", \"BIGTIFF=YES\"])\n",
    "    outRaster.SetGeoTransform(geoTransform)\n",
    "    outRaster.SetProjection(projection)\n",
    "    band = outRaster.GetRasterBand(1)\n",
    "    assert band is not None\n",
    "    if noDataValue is not None:\n",
    "        band.SetNoDataValue(noDataValue)\n",
    "    band.WriteArray(dataArray)\n",
    "    band = None\n",
    "    outRaster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip one or more files, without any filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Temp\\\\dataprep\\\\gbd2016_polygons\\\\from_map_db\\\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the files to process \n",
    "#inFilePattern = r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_*_adm_2.tif'\n",
    "#inFiles = glob.glob(inFilePattern)\n",
    "\n",
    "# or for one file only\n",
    "#inFiles = [r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\2015.ITN.use.yearavg.adj.stable.tif']\n",
    "#inFiles = [r'\\\\129.67.26.176\\map_data\\dengue_project\\clean_mastergrids\\evidence_consensus\\Dengue_EBC_June2015\\EBC_June2015_MG.Extent.tif']\n",
    "#inFiles = [r'\\\\map-fs1.ndph.ox.ac.uk\\map_data\\hsg\\DataPrep\\IHME_population\\comp\\IHME_admin_IDs.tif']\n",
    "#inFiles = [r'E:\\Temp\\pop\\un\\02_processing\\01_gaul_to_mastergrid\\gaul_admin0_rasterized2.tif']\n",
    "inFiles = [r'C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif']\n",
    "\n",
    "inFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data (matching resolution)\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\dataprep\\gbd2016_polygons\\from_map_db\\rds_gaul_adm_1_with_placeholder_in_gaps_only.tif\n",
      "Clipped 806417 data cells that were outside provided limits\n",
      "Filled 224204 total cells within limits from nearby data\n",
      "Failed to fill 0 total cells within limits due to no data cells in range\n"
     ]
    }
   ],
   "source": [
    "for inFileName in inFiles:\n",
    "    print inFileName\n",
    "\n",
    "    outDataFile = os.path.splitext(inFileName)[0] + \".MG_Matched.tif\"\n",
    "    outFailFile = os.path.splitext(inFileName)[0] + \".MG_Errors.tif\"\n",
    "    inDS = gdal.Open(inFileName)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection() \n",
    "    \n",
    "    dTypeIn = bData.DataType\n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    # (or satisfy yourself that they're close)\n",
    "  #  assert gtIn[1] == gtLand[1]\n",
    "   # assert gtIn[5] == gtLand[5]\n",
    "    \n",
    "    # the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "    landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "    landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "    #print (landOffsetN, landOffsetW)\n",
    "    \n",
    "    # read the whole data file\n",
    "    inData = bData.ReadAsArray().astype(long) #astype(np.float32)\n",
    "    inDS = None\n",
    "    # read the relevant parts of the land file\n",
    "    inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "    \n",
    "    # Dataset-specific munging: \n",
    "    # some files have been created badly: they have one nodata value of e.g. -3.4e38, \n",
    "    # but ALSO contain pixels at -9999 which should be taken as nodata (probably some dumb\n",
    "    # R thing which always writes nodata as -9999 regardless of what the file is set to)\n",
    "    # Replace those\n",
    "    if ndvIn != -9999:\n",
    "        inData[inData==-9999] = ndvIn\n",
    "    # Alternatively or also, set ALL nodata pixels to -9999 \n",
    "    # as a maxvalue +ve nodata value doesn't work reliably e.g. arcmap might \n",
    "    # report -1xxxIND for the stats\n",
    "    # It doesn't even work reliably here (it's to do with the precision of the tiff format, \n",
    "    # most likely), or sometimes the large negative values get read as -inf (which fails equality \n",
    "    # test with everything) \n",
    "    # So just set all values beyond a reasonable limit to be nodata\n",
    "    inData[abs(inData) > 10e7] = -9999\n",
    "    inData[inData == 0] = -9999\n",
    "    ndvIn = -9999\n",
    "    \n",
    "    # Clip but do not fill (the only change needed to also fill would be to choose it here)\n",
    "    errors = spreadToCoast(inData, inLand, _NDV=ndvIn, applyClip=1, applyFill=1, nearestNPixels=1, searchRadius=20)\n",
    "    \n",
    "    # write the data\n",
    "    writeTiffFile(inData, outDataFile, gtIn, projIn, ndvIn, dTypeIn) #gdal.GDT_Float32 )\n",
    "\n",
    "    # write the failures grid (no nodata)\n",
    "    writeTiffFile(np.asarray(errors), outFailFile, gtIn, projIn, None, gdal.GDT_Byte)\n",
    "#landDS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dTypeIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced use - match to a limits surface and a coastline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we want to ensure that we have data within the entirety of the Pf limits surface (stable or unstable) but none in the sea. \n",
    "\n",
    "However we don't want data on _all_ land, so we run as a two-stage process: first we spread to the limits layer, then separately clip to the coastline.\n",
    "\n",
    "(Alternatively we could clip the limits layer to the coastline, then use that for a clip-and-fill on the data).\n",
    "\n",
    "This workflow assumes that the limits has at least as large an extent as the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The coastal data should be global and the limits (fill-to) mask should be at least as large as the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the data locations\n",
    "inDir = r'C:\\Temp\\PV_Alignment'\n",
    "inFN = 'PvPR_Aug2015_2_Clip1_Copy.tif'\n",
    "inLimsFN = 'PvPR_2010_5k.flt' # 'pvlims5f_5k.tif'\n",
    "\n",
    "outFN = 'PvPR_Aug2015_2_Clip1_Copy_FilledToPvPRLims.tif'\n",
    "outFailFN = 'PvPR_Aug2015_2_Clip1_Copy_PvPRLimsFillFailures.tif'\n",
    "\n",
    "inFile = os.path.join(inDir, inFN)\n",
    "inLimsFile = os.path.join(inDir, inLimsFN)\n",
    "\n",
    "outDataFile = os.path.join(inDir, outFN)\n",
    "outFailFile = os.path.join(inDir, outFailFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the coastline data\n",
    "landDS = gdal.Open(coastlineFile)\n",
    "bLand = landDS.GetRasterBand(1)\n",
    "ndvLand = bLand.GetNoDataValue()\n",
    "gtLand = landDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the whole extent of the data\n",
    "inDS = gdal.Open(inFile)\n",
    "bData = inDS.GetRasterBand(1)\n",
    "ndvIn = bData.GetNoDataValue()\n",
    "gtIn = inDS.GetGeoTransform()\n",
    "projIn = inDS.GetProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure the resolutions match (not actually checking the alignment)\n",
    "assert gtIn[1] == gtLand[1]\n",
    "assert gtIn[5] == gtLand[5]\n",
    "\n",
    "assert gtIn[1] == gtLims[1]\n",
    "assert gtIn[5] == gtLims[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work out which bits of the mask files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the global coastline image?\n",
    "landOffsetW = int((gtIn[0]-gtLand[0]) / gtLand[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN = int((gtIn[3]-gtLand[3]) / gtLand[5])\n",
    "landOffsetN, landOffsetW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the input dataset is not necessarily global; where does it sit in the maybe-global clipping image?\n",
    "maskOffsetW = int((gtIn[0]-gtLims[0]) / gtLims[1])\n",
    "#landOffsetN = int((gtPop[3]-gtLand[3]) / gtLand[5])\n",
    "maskOffsetN = int((gtIn[3]-gtLims[3]) / gtLims[5])\n",
    "maskOffsetN, maskOffsetW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all the data file\n",
    "inData = bData.ReadAsArray(dataOffsetW, dataOffsetN, dataReadXSize, dataReadYSize).astype(np.float32)\n",
    "inDataOrig = bData.ReadAsArray()\n",
    "# read the relevant parts of the land and mask files\n",
    "inLand = bLand.ReadAsArray(landOffsetW, landOffsetN, inData.shape[1], inData.shape[0])\n",
    "inMask = bLims.ReadAsArray(maskOffsetW, maskOffsetN, inData.shape[1], inData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the limits data (specific to this dataset) - reclass the pv limits values into a 0-1 mask for data / nodata\n",
    "# NB keeping \"0\" as \"data\"\n",
    "#inMask[inMask!=3] = 10\n",
    "#inMask[inMask==3] = 0\n",
    "#inMask[inMask==10] = 1\n",
    "inMask[inMask != ndvMask] = 1\n",
    "inMask[inMask == ndvMask] = 0\n",
    "inMask = inMask.astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndvMask, ndvLand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the fill and clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the spreading to generate values for all pixels of the limits surface\n",
    "# but do not clip to it, because the new Pv data covers more areas (e.g. algeria)\n",
    "# than the limits\n",
    "errors = spreadToCoast(inData, inMask, _NDV=ndvIn, applyClip=0, applyFill=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now clip the data to the coastline, but do not fill (as we don't want to fill into all land)\n",
    "clipErrors = spreadToCoast(inData, inLand, _NDV=ndvIn, applyClip=1, applyFill=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the data\n",
    "writeTiffFile(inData, outDataFile, gtIn, projIn, ndvIn, gdal.GDT_Float32 )\n",
    "\n",
    "# write the failures grid (no nodata)\n",
    "writeTiffFile(np.asarray(errors), outFailFile, gtIn, projIn, None, gdal.GDT_Byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage 2 - match multiple files of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have multiple input / data files that must be matched to a single limits layer. We want data in the cells of the limits layer and *only* those cells, i.e. we want to both fill to and clip to the limits layer.\n",
    "\n",
    "(The limits layer was in fact created by clipping to the coastline using the first workflow above, so we are then effectively clipping to the coastline at the same time).\n",
    "\n",
    "The limits layer is not global, and some of the data file may cover a larger extent than the limits: so we need to read the limits into the appropriate part of an array of the same size as the data file each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inFilePattern = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\*.tif'\n",
    "inFiles = glob.glob(inFilePattern)\n",
    "outDir = r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the ITN file will be used as our limits layer \n",
    "inFiles.index(r'C:\\Users\\zool1301\\Documents\\Dial-A-Map\\PWG-20160324-FairlyUrgentButNotTooOnerous\\2015.ITN.use.yearavg.adj.stable.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limsFile = inFiles.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the limits data\n",
    "limsDS = gdal.Open(inLimsFile)\n",
    "bLims = limsDS.GetRasterBand(1)\n",
    "ndvMask = bLims.GetNoDataValue()\n",
    "gtLims = limsDS.GetGeoTransform()\n",
    "\n",
    "for inFile in inFiles:\n",
    "    # Read the whole extent of the data each time\n",
    "    print \"__________________________________________\"\n",
    "    print inFile\n",
    "    inDS = gdal.Open(inFile)\n",
    "    bData = inDS.GetRasterBand(1)\n",
    "    ndvIn = bData.GetNoDataValue()\n",
    "    gtIn = inDS.GetGeoTransform()\n",
    "    projIn = inDS.GetProjection()\n",
    "\n",
    "    # Ensure the resolutions match (not actually checking the alignment)\n",
    "    assert gtIn[1] == gtLims[1]\n",
    "    assert gtIn[5] == gtLims[5]\n",
    "    # read all the data file\n",
    "    inData = bData.ReadAsArray().astype(np.float32)\n",
    "    inDataOrig = bData.ReadAsArray()\n",
    "    \n",
    "    # Create an array for the limits that is the same size as the data, then read the appropriate \n",
    "    # part of the limits into the appropriate part of this array\n",
    "    inMask = np.empty(shape=inData.shape)\n",
    "    inMask[:] = ndvMask\n",
    "    \n",
    "    # how many pixels from the W edge of the limits does the W edge of the data sit?\n",
    "    # This will be negative if the data goes further west than the limits\n",
    "    maskOffsetW = int((gtIn[0] - gtLims[0]) / gtLims[1])\n",
    "    # how many pixels from the N edge of the limits does the N edge of the data sit?\n",
    "    # This will be negative if the data goes further north than the limits\n",
    "    maskOffsetN = int((gtIn[3] - gtLims[3]) / gtLims[5])\n",
    "    print \"Mask offsets are \"+str((maskOffsetN, maskOffsetW))\n",
    "    \n",
    "    # find the top left corner (in the data) of the limits we can read\n",
    "    if maskOffsetN < 0:\n",
    "        maskInDataOffsetN = abs(maskOffsetN) + 1\n",
    "        maskOffsetN = 0\n",
    "    else:\n",
    "        maskInDataOffsetN = 0\n",
    "    \n",
    "    if maskOffsetW < 0:\n",
    "        maskInDataOffsetW = abs(maskOffsetW) + 1\n",
    "        maskOffsetW = 0\n",
    "    else:\n",
    "        maskInDataOffsetW = 0\n",
    "    \n",
    "    dataYSize, dataXSize = inData.shape\n",
    "    maskYSize = limsDS.RasterYSize\n",
    "    maskXSize = limsDS.RasterXSize\n",
    "    \n",
    "    # find how large the limits array we can read is\n",
    "    if maskOffsetW + dataXSize > maskXSize:\n",
    "        # the data goes beyond the E edge of the mask; read to the mask's edge\n",
    "        maskReadXSize = maskXSize - maskOffsetW\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadXSize = dataXSize\n",
    "    if maskOffsetN + dataYSize > maskYSize:\n",
    "        # the data goes beyond the S edge of the mask; read to the mask's edge\n",
    "        maskReadYSize = maskYSize - maskOffsetN\n",
    "    else:\n",
    "        # the data does not go beyond the E edge of the mask, read to the data's size\n",
    "        maskReadYSize = dataYSize\n",
    "        \n",
    "    if (maskInDataOffsetN > 0 or maskInDataOffsetW > 0):\n",
    "        print inFile + \" has greater extent than limits, reading mask as offset!\"\n",
    "    \n",
    "    # read the relevant part of the mask file into the relevant part of the pre-prepared \n",
    "    # mask array (leaving any other part as nodata)\n",
    "    inMask[maskInDataOffsetN:maskInDataOffsetN + maskReadYSize,\n",
    "           maskInDataOffsetW:maskInDataOffsetW + maskReadXSize] = bLims.ReadAsArray(\n",
    "    maskOffsetW, maskOffsetN, maskReadXSize, maskReadYSize)\n",
    "    \n",
    "    # specific task for this mask image: the mask image wasn't actually a mask; \n",
    "    # we just want to use anywhere that it wasn't nodata as our mask, so reclass it\n",
    "    inMask[inMask != ndvMask] = 1\n",
    "    inMask[inMask == ndvMask] = 0\n",
    "    inMask = inMask.astype(np.byte)\n",
    "    \n",
    "    # Specific task for these data images: \n",
    "    # We have been asked to set all locations within the limits, where the data image \n",
    "    # is nodata, to zero, rather than filling based on nearest neighbours.\n",
    "    # Also some images have nodata as -inf which doesn't play nicely with equality test,\n",
    "    # so look for anything with an enormous negative value.\n",
    "    inData[np.logical_and(np.logical_or(inData==ndvIn, inData<-1e100),\n",
    "                          inMask == 1)] = 0\n",
    "    \n",
    "    # Spread and clip to the mask dataset only (the fill should not result in any \n",
    "    # cells being filled, due to the above step: we could turn it off)\n",
    "    errors = spreadToCoast(inData, inMask, _NDV=ndvIn, applyClip=1, applyFill=1)\n",
    "    \n",
    "    outDataFile = inFile.replace(\".tif\", \".MG_Matched.LimsClipped.tif\")\n",
    "    # write the data - the geotransform is unchanged as we worked with the data extent\n",
    "    # not the mask extent\n",
    "    writeTiffFile(inData, outDataFile, gtIn, projIn, ndvIn, gdal.GDT_Float32 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
