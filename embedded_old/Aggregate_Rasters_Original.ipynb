{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for aggregating (resampling down) rasters, for example to convert the MODIS 30 arcsecond (~1km) grids into 2.5 arcminute (~5km) grids.\n",
    "\n",
    "Code is provided for aggregating continuous or categorical rasters, along with various example input commands.\n",
    "\n",
    "Continuous rasters can be aggregated to produce any/all of count, max, mean, min, range, sum, or std dev of the input cells.\n",
    "\n",
    "Categorical rasters can be aggregated to produce one class proportion and one like adjacency grid for each of the input values, and a single majority grid. This assumes that the input grids have a small-ish number of unique values, and that they start from zero (it was written for the MCD12Q1 BRDF landcover data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "#import scipy.ndimage as ndi\n",
    "%load_ext cython\n",
    "import glob\n",
    "import os\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%%cython --compile-args=/openmp --link-args=/openmp --force\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport openmp\n",
    "from cython.parallel import parallel, prange\n",
    "from libc.math cimport sqrt\n",
    "   \n",
    "@cython.boundscheck(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.wraparound(False)\n",
    "cpdef aggregateContinuous(float [:,::1] data, int fact, float _NDV = np.inf, char minMaxRangeSumOnly = 0):\n",
    "    ''' Aggregates a continuous raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
    "\n",
    "     Returns a tuple containing up to seven grids at the aggregated resolution, \n",
    "     each representing a different summary of the source pixels covered by each output\n",
    "     pixel, namely:\n",
    "        (\n",
    "          Count, \n",
    "          Max, \n",
    "          Mean (or None), \n",
    "          Min, \n",
    "          Range, \n",
    "          Sum, \n",
    "          SD (or None)\n",
    "        )\n",
    "     The input grid must (in this implementation) have dimensions that are \n",
    "     exact multiples of aggregation factor.\n",
    "    '''    \n",
    "    cdef:\n",
    "        Py_ssize_t xShapeIn, yShapeIn, xShapeOut, yShapeOut\n",
    "        Py_ssize_t xIn, yIn, xOut, yOut, catNum\n",
    "        int yBelow, yAbove, xLeft, xRight\n",
    "        float localValue\n",
    "        float[:,::1] outputMeanArr\n",
    "        float[:,::1] outputMinArr\n",
    "        float[:,::1] outputMaxArr\n",
    "        float[:,::1] outputRangeArr\n",
    "        float[:,::1] outputSumArr\n",
    "        float[:,::1] outputSDArr\n",
    "        \n",
    "        float[:,::1] _oldSDArr\n",
    "        float[:,::1] _oldMeanArr\n",
    "        \n",
    "        int[:,::1] outputCountArr\n",
    "        float proportion\n",
    "        double variance\n",
    "        \n",
    "    yShapeIn = data.shape[0]\n",
    "    xShapeIn = data.shape[1]\n",
    "    \n",
    "    assert fact > 0\n",
    "    assert yShapeIn % fact == 0\n",
    "    assert xShapeIn % fact == 0\n",
    "    \n",
    "    # how much of an output cell does each input cell account for\n",
    "    proportion = 1.0 / (fact**2)\n",
    "    \n",
    "    yShapeOut = yShapeIn / fact\n",
    "    xShapeOut = xShapeIn / fact\n",
    "    \n",
    "    outputMinArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    outputMaxArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    \n",
    "    if not minMaxRangeSumOnly:\n",
    "        outputMeanArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "        outputSDArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    \n",
    "        _oldSDArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "        _oldMeanArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "        \n",
    "        outputMeanArr[:] = _NDV\n",
    "        outputSDArr[:] = _NDV\n",
    "    \n",
    "        _oldMeanArr[:] = _NDV\n",
    "        _oldSDArr[:] = _NDV\n",
    "    \n",
    "    \n",
    "    outputMinArr[:] = np.inf\n",
    "    outputMaxArr[:] = -np.inf\n",
    "    \n",
    "    outputSumArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    outputRangeArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    outputCountArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.int32)\n",
    "    \n",
    "    #with nogil, parallel():\n",
    "    # no parallel written this way round as the min/max values would be non deterministic\n",
    "    if 1:\n",
    "        #yOut = -1\n",
    "        #xOut = -1\n",
    "        #localValue = -1\n",
    "        for yIn in range(yShapeIn):\n",
    "            yAbove = yIn - 1\n",
    "            if yIn == 0:\n",
    "                yAbove = -1\n",
    "            yBelow = yIn+1\n",
    "            if yIn == yShapeIn-1:\n",
    "                yBelow = -1\n",
    "            yOut = <int> yIn / fact\n",
    "            localValue=-1\n",
    "            xOut = -1\n",
    "            for xIn in range(xShapeIn):\n",
    "                xLeft = xIn - 1\n",
    "                if xIn == 0:\n",
    "                    xLeft = -1\n",
    "                xRight = xIn+1\n",
    "                if xIn == xShapeIn-1:\n",
    "                    xRight = -1\n",
    "                xOut = <int> xIn / fact\n",
    "                \n",
    "                localValue = data[yIn, xIn]\n",
    "                if localValue == _NDV:\n",
    "                    continue\n",
    "                # Max and Min\n",
    "                if localValue > outputMaxArr[yOut, xOut]:\n",
    "                    outputMaxArr[yOut, xOut] = localValue\n",
    "                if localValue < outputMinArr[yOut, xOut]:\n",
    "                    outputMinArr[yOut, xOut] = localValue\n",
    "                # Sum and Count\n",
    "                outputSumArr[yOut, xOut] += localValue\n",
    "                outputCountArr[yOut, xOut] += 1\n",
    "                if not minMaxRangeSumOnly:\n",
    "                    # Running mean and SD\n",
    "                    if outputCountArr[yOut, xOut] == 1:\n",
    "                        _oldMeanArr[yOut, xOut] = localValue\n",
    "                        outputMeanArr[yOut, xOut] = localValue\n",
    "                        _oldSDArr[yOut, xOut] = 0\n",
    "                        outputSDArr[yOut, xOut] = 0\n",
    "                    else:\n",
    "                        outputMeanArr[yOut, xOut] = (_oldMeanArr[yOut, xOut] + \n",
    "                                                     ((localValue - _oldMeanArr[yOut, xOut]) / \n",
    "                                                          outputCountArr[yOut, xOut]))\n",
    "                        outputSDArr[yOut, xOut] = (_oldSDArr[yOut, xOut] +\n",
    "                                                   ((localValue - _oldMeanArr[yOut, xOut]) *\n",
    "                                                    (localValue - outputMeanArr[yOut, xOut])\n",
    "                                                    ))\n",
    "                        _oldMeanArr[yOut, xOut] = outputMeanArr[yOut, xOut]\n",
    "                        _oldSDArr[yOut, xOut] = outputSDArr[yOut, xOut]\n",
    "\n",
    "    for yOut in range(yShapeOut): # not bothering to parallelise this, there are frac**2 fewer cells than before\n",
    "        xOut = -1\n",
    "        for xOut in range(xShapeOut):\n",
    "            if outputCountArr[yOut, xOut] == 0:\n",
    "                outputMinArr[yOut, xOut] = _NDV\n",
    "                outputMaxArr[yOut, xOut] = _NDV\n",
    "                outputRangeArr[yOut, xOut] = _NDV\n",
    "                outputSumArr[yOut, xOut] = _NDV\n",
    "                if not minMaxRangeSumOnly:\n",
    "                    outputMeanArr[yOut, xOut] = _NDV\n",
    "                #continue\n",
    "            else:\n",
    "                # min, max, sum, count are already set\n",
    "                outputRangeArr[yOut, xOut] = outputMaxArr[yOut, xOut] - outputMinArr[yOut, xOut]\n",
    "                if not minMaxRangeSumOnly:\n",
    "                    variance = outputSDArr[yOut, xOut] / outputCountArr[yOut, xOut]\n",
    "                    outputSDArr[yOut, xOut] = sqrt(variance)\n",
    "                    # re-calculate the mean using simple sum/n as the running mean method is more \n",
    "                    # likely to have accumulated (slight) fp errors (in practice they seem to match \n",
    "                    # to around 1e-6 but this will depend on the size of the values)\n",
    "                    outputMeanArr[yOut, xOut] = outputSumArr[yOut, xOut] / outputCountArr[yOut, xOut]\n",
    "    #return np.round(np.asarray(outputArr)).astype(np.uint8)\n",
    "    if not minMaxRangeSumOnly:\n",
    "        return { # count, max, mean, min, range, sum\n",
    "            \"count\": np.asarray(outputCountArr),\n",
    "            \"max\": np.asarray(outputMaxArr),\n",
    "            \"mean\": np.asarray(outputMeanArr).astype(np.float32),\n",
    "            \"min\": np.asarray(outputMinArr),\n",
    "            \"range\": np.asarray(outputRangeArr),\n",
    "            \"sum\": np.asarray(outputSumArr),\n",
    "            \"sd\": np.asarray(outputSDArr).astype(np.float32),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"count\": np.asarray(outputCountArr),\n",
    "            \"max\": np.asarray(outputMaxArr),\n",
    "            \"mean\": None, #np.asarray(outputMeanArr).astype(np.float32),\n",
    "            \"min\": np.asarray(outputMinArr),\n",
    "            \"range\": np.asarray(outputRangeArr),\n",
    "            \"sum\": np.asarray(outputSumArr),\n",
    "            \"sd\": None # np.asarray(outputSDArr).astype(np.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%%cython --compile-args=/openmp --link-args=/openmp --force --annotate\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport openmp\n",
    "from cython.parallel import parallel, prange\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.wraparound(False)\n",
    "cdef class RasterAggregator_float:\n",
    "    ''' Aggregates a continuous raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
    "\n",
    "     Returns a tuple containing up to seven grids at the aggregated resolution, \n",
    "     each representing a different summary of the source pixels covered by each output\n",
    "     pixel, namely:\n",
    "        (\n",
    "          Count, \n",
    "          Max, \n",
    "          Mean (or None), \n",
    "          Min, \n",
    "          Range, \n",
    "          Sum, \n",
    "          SD (or None)\n",
    "        )\n",
    "    '''    \n",
    "   \n",
    "    cdef:\n",
    "        Py_ssize_t xShapeOut, yShapeOut\n",
    "        Py_ssize_t xShapeIn, yShapeIn, tileXShapeIn, tileYShapeIn\n",
    "        \n",
    "    cdef:\n",
    "        \n",
    "        float _NDV\n",
    "        char minMaxRangeSumOnly\n",
    "        \n",
    "        float[:,::1] outputMeanArr\n",
    "        float[:,::1] outputMinArr\n",
    "        float[:,::1] outputMaxArr\n",
    "        float[:,::1] outputRangeArr\n",
    "        float[:,::1] outputSumArr\n",
    "        float[:,::1] outputSDArr\n",
    "        \n",
    "        float[:,::1] _oldSDArr\n",
    "        float[:,::1] _oldMeanArr\n",
    "        \n",
    "        int[:,::1] outputCountArr\n",
    "        \n",
    "        char[:,::1] _coverageArr\n",
    "        \n",
    "        float proportion\n",
    "        double variance\n",
    "        double xFact, yFact\n",
    "    \n",
    "    @cython.boundscheck(False)\n",
    "    @cython.cdivision(True)\n",
    "    @cython.wraparound(False)\n",
    "    def __cinit__(self, xSizeIn, ySizeIn, xSizeOut, ySizeOut, _NDV, minMaxRangeSumOnly):\n",
    "        assert xSizeIn > xSizeOut\n",
    "        assert ySizeIn > ySizeOut\n",
    "        \n",
    "        self.xShapeIn = xSizeIn\n",
    "        self.yShapeIn = ySizeIn\n",
    "        self.xShapeOut = xSizeOut\n",
    "        self.yShapeOut = ySizeOut\n",
    "        \n",
    "        self.minMaxRangeSumOnly = minMaxRangeSumOnly\n",
    "        \n",
    "        self.xFact = <double>self.xShapeIn / self.xShapeOut\n",
    "        self.yFact = <double>self.yShapeIn / self.yShapeOut\n",
    "        \n",
    "        # how much of an output cell does each input cell account for\n",
    "        self.proportion = 1.0 / (self.xFact * self.yFact)\n",
    "        \n",
    "        # initialise the output arrays\n",
    "        self.outputMinArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "        self.outputMaxArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "        self.outputSumArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "        self.outputRangeArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "        self.outputCountArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.int32)\n",
    "        self.outputMinArr[:] = np.inf\n",
    "        self.outputMaxArr[:] = -np.inf\n",
    "        self._coverageArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.byte)\n",
    "        \n",
    "        if not minMaxRangeSumOnly:\n",
    "            self.outputMeanArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "            self.outputSDArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "    \n",
    "            self._oldSDArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "            self._oldMeanArr = np.zeros(shape=(ySizeOut, xSizeOut), dtype = np.float32)\n",
    "        \n",
    "            self.outputMeanArr[:] = _NDV\n",
    "            self.outputSDArr[:] = _NDV\n",
    "    \n",
    "            self._oldMeanArr[:] = _NDV\n",
    "            self._oldSDArr[:] = _NDV\n",
    "    \n",
    "    @cython.boundscheck(False)\n",
    "    @cython.cdivision(True)\n",
    "    @cython.wraparound(False)\n",
    "    cpdef addTile(self, float[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "        cdef:\n",
    "            Py_ssize_t tileYShapeIn, tileXShapeIn\n",
    "            int yBelow, yAbove, xLeft, xRight\n",
    "            Py_ssize_t xInGlobal, xInTile, yInGlobal, yInTile\n",
    "            float localValue\n",
    "            Py_ssize_t xOut, yOut\n",
    "        tileYShapeIn = data.shape[0]\n",
    "        tileXShapeIn = data.shape[1]\n",
    "        \n",
    "        for yInTile in range(tileYShapeIn):\n",
    "            yInGlobal = yInTile + yOffset\n",
    "            yAbove = yInGlobal - 1\n",
    "            if yInGlobal == 0:\n",
    "                yAbove = -1\n",
    "            yBelow = yInGlobal+1\n",
    "            if yInGlobal == self.yShapeIn-1:\n",
    "                yBelow = -1\n",
    "            yOut = <int> (yInGlobal / self.yFact)\n",
    "            localValue=-1\n",
    "            xOut = -1\n",
    "            for xInTile in range(tileXShapeIn):\n",
    "                xInGlobal = xInTile + xOffset\n",
    "                xLeft = xInGlobal - 1\n",
    "                if xInGlobal == 0:\n",
    "                    xLeft = -1\n",
    "                xRight = xInGlobal + 1\n",
    "                if xInGlobal == self.xShapeIn - 1:\n",
    "                    xRight = -1\n",
    "                xOut = <int> (xInGlobal / self.xFact)\n",
    "                \n",
    "                self._coverageArr[yOut, xOut] = 1\n",
    "                \n",
    "                localValue = data[yInTile, xInTile]\n",
    "                if localValue == self._NDV:\n",
    "                    continue\n",
    "                # Max and Min\n",
    "                if localValue > self.outputMaxArr[yOut, xOut]:\n",
    "                    self.outputMaxArr[yOut, xOut] = localValue\n",
    "                if localValue < self.outputMinArr[yOut, xOut]:\n",
    "                    self.outputMinArr[yOut, xOut] = localValue\n",
    "                # Sum and Count\n",
    "                self.outputSumArr[yOut, xOut] += localValue\n",
    "                self.outputCountArr[yOut, xOut] += 1\n",
    "                if not self.minMaxRangeSumOnly:\n",
    "                    # Running mean and SD\n",
    "                    if self.outputCountArr[yOut, xOut] == 1:\n",
    "                        self._oldMeanArr[yOut, xOut] = localValue\n",
    "                        self.outputMeanArr[yOut, xOut] = localValue\n",
    "                        self._oldSDArr[yOut, xOut] = 0\n",
    "                        self.outputSDArr[yOut, xOut] = 0\n",
    "                    else:\n",
    "                        self.outputMeanArr[yOut, xOut] = (self._oldMeanArr[yOut, xOut] + \n",
    "                                                     ((localValue - self._oldMeanArr[yOut, xOut]) / \n",
    "                                                          self.outputCountArr[yOut, xOut]))\n",
    "                        self.outputSDArr[yOut, xOut] = (self._oldSDArr[yOut, xOut] +\n",
    "                                                   ((localValue - self._oldMeanArr[yOut, xOut]) *\n",
    "                                                    (localValue - self.outputMeanArr[yOut, xOut])\n",
    "                                                    ))\n",
    "                        self._oldMeanArr[yOut, xOut] = self.outputMeanArr[yOut, xOut]\n",
    "                        self._oldSDArr[yOut, xOut] = self.outputSDArr[yOut, xOut]\n",
    "    \n",
    "    @cython.boundscheck(False)\n",
    "    @cython.cdivision(True)\n",
    "    @cython.wraparound(False)\n",
    "    cdef finalise(self):\n",
    "        cdef:\n",
    "            Py_ssize_t xOut, yOut\n",
    "            float variance\n",
    "            float iscomplete = 1\n",
    "        for yOut in range(self.yShapeOut): # not bothering to parallelise this, there are frac**2 fewer cells than before\n",
    "            xOut = -1\n",
    "            if self._coverageArr[yOut, xOut] == 0:\n",
    "                iscomplete = 0\n",
    "            for xOut in range(self.xShapeOut):\n",
    "                if self.outputCountArr[yOut, xOut] == 0:\n",
    "                    self.outputMinArr[yOut, xOut] = self._NDV\n",
    "                    self.outputMaxArr[yOut, xOut] = self._NDV\n",
    "                    self.outputRangeArr[yOut, xOut] = self._NDV\n",
    "                    self.outputSumArr[yOut, xOut] = self._NDV\n",
    "                    if not self.minMaxRangeSumOnly:\n",
    "                        self.outputMeanArr[yOut, xOut] = self._NDV\n",
    "                    #continue\n",
    "                else:\n",
    "                    # min, max, sum, count are already set\n",
    "                    self.outputRangeArr[yOut, xOut] = (\n",
    "                        self.outputMaxArr[yOut, xOut] - self.outputMinArr[yOut, xOut])\n",
    "                    if not self.minMaxRangeSumOnly:\n",
    "                        variance = self.outputSDArr[yOut, xOut] / self.outputCountArr[yOut, xOut]\n",
    "                        self.outputSDArr[yOut, xOut] = sqrt(variance)\n",
    "                        # re-calculate the mean using simple sum/n as the running mean method is more \n",
    "                        # likely to have accumulated (slight) fp errors (in practice they seem to match \n",
    "                        # to around 1e-6 but this will depend on the size of the values)\n",
    "                        self.outputMeanArr[yOut, xOut] = (\n",
    "                            self.outputSumArr[yOut, xOut] / self.outputCountArr[yOut, xOut])\n",
    "        if not iscomplete:\n",
    "            print \"Warning, generating a result without having received input data for full extent\"\n",
    "    \n",
    "    @cython.boundscheck(False)\n",
    "    @cython.cdivision(True)\n",
    "    @cython.wraparound(False)\n",
    "    cpdef GetResults(self):\n",
    "        self.finalise()\n",
    "        #return np.round(np.asarray(outputArr)).astype(np.uint8)\n",
    "        if not self.minMaxRangeSumOnly:\n",
    "            return { # count, max, mean, min, range, sum\n",
    "                \"count\": np.asarray(self.outputCountArr),\n",
    "                \"max\": np.asarray(self.outputMaxArr),\n",
    "                \"mean\": np.asarray(self.outputMeanArr).astype(np.float32),\n",
    "                \"min\": np.asarray(self.outputMinArr),\n",
    "                \"range\": np.asarray(self.outputRangeArr),\n",
    "                \"sum\": np.asarray(self.outputSumArr),\n",
    "                \"sd\": np.asarray(self.outputSDArr).astype(np.float32),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"count\": np.asarray(self.outputCountArr),\n",
    "                \"max\": np.asarray(self.outputMaxArr),\n",
    "                \"min\": np.asarray(self.outputMinArr),\n",
    "                \"range\": np.asarray(self.outputRangeArr),\n",
    "                \"sum\": np.asarray(self.outputSumArr),\n",
    "            }\n",
    "\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=/openmp --link-args=/openmp --force\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport openmp\n",
    "from cython.parallel import parallel, prange\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.cdivision(True)\n",
    "@cython.wraparound(False)\n",
    "# aggregates a grid by a specified factor (e.g. 10 to aggegate 500m to 5km data),\n",
    "# producing for each class specified in the input data a grid at the output \n",
    "# resolution for each of fraction and like adjacency.\n",
    "# Like adjacencies are calculated using double-count method whereas Dan's IDL\n",
    "# code used single-count method, so results are slightly different.\n",
    "# Designed for use with MCD12Q1 IBGP landcover data, a couple of classes are hardcoded\n",
    "# to suit this, but they could easily be modified.\n",
    "cpdef aggregateStats(unsigned int[:,::1] landCover, int fact, int nCategories, float fltNDV = -9999):\n",
    "    ''' Aggregates a categorical raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
    "\n",
    "     Returns a tuple containing two three dimensional grids and one two dimensional grid \n",
    "     at the aggregated resolution, each representing a different summary of the source \n",
    "     pixels covered by each output pixel, namely:\n",
    "        (\n",
    "          Fraction (3D), \n",
    "          Like-Adjacency (3D), \n",
    "          Majority (2D)\n",
    "        )\n",
    "     The fraction and like adjacency outputs have one image (in the z dimension) for each category\n",
    "     (value) of the input raster. It's assumed that the input has values from zero and the mapping \n",
    "     is therefore between the input value and the output position, i.e. an input pixel of value 4\n",
    "     will contribute to the 4th grid in the output stack. This is suitable for use with IGBP \n",
    "     landcover data.\n",
    "\n",
    "     The input grid must (in this implementation) have dimensions that are \n",
    "     exact multiples of aggregation factor.\n",
    "    '''    \n",
    "    cdef:\n",
    "        Py_ssize_t xShapeIn, yShapeIn, xShapeOut, yShapeOut\n",
    "        Py_ssize_t xIn, yIn, xOut, yOut, catNum\n",
    "        int yBelow, yAbove, xLeft, xRight\n",
    "        unsigned char localValue\n",
    "        float[:,:,::1] outputFracArr\n",
    "        float[:,:,::1] outputLikeAdjArr\n",
    "        unsigned int [:,::1] outputMajorityArr\n",
    "        float [:,::1] tmpMajorityPropArr\n",
    "        float proportion\n",
    "        \n",
    "    yShapeIn = landCover.shape[0]\n",
    "    xShapeIn = landCover.shape[1]\n",
    "    \n",
    "    assert fact > 0\n",
    "    assert yShapeIn % fact == 0\n",
    "    assert xShapeIn % fact == 0\n",
    "    \n",
    "    # how much of an output cell does each input cell account for\n",
    "    proportion = 1.0 / (fact**2)\n",
    "    \n",
    "    yShapeOut = yShapeIn / fact\n",
    "    xShapeOut = xShapeIn / fact\n",
    "    outputFracArr = np.zeros(shape=(nCategories, yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    outputLikeAdjArr = np.zeros(shape=(nCategories, yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    outputMajorityArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.int32)\n",
    "    tmpMajorityPropArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
    "    \n",
    "    with nogil, parallel():\n",
    "        #yOut = -1\n",
    "        #xOut = -1\n",
    "        #localValue = -1\n",
    "        for yIn in prange(yShapeIn):\n",
    "            yAbove = yIn - 1\n",
    "            if yIn == 0:\n",
    "                yAbove = -1\n",
    "            yBelow = yIn+1\n",
    "            if yIn == yShapeIn-1:\n",
    "                yBelow = -1\n",
    "            yOut = <int> yIn / fact\n",
    "            localValue=-1\n",
    "            xOut = -1\n",
    "            for xIn in range(xShapeIn):\n",
    "                xLeft = xIn - 1\n",
    "                if xIn == 0:\n",
    "                    xLeft = -1\n",
    "                xRight = xIn+1\n",
    "                if xIn == xShapeIn-1:\n",
    "                    xRight = -1\n",
    "                xOut = <int> xIn / fact\n",
    "                \n",
    "                # fractional landcover\n",
    "                localValue = landCover[yIn, xIn]\n",
    "                # hardcode a remap from the high values into the next available smallest ones\n",
    "                if localValue == 254:\n",
    "                    localValue = 17\n",
    "                elif localValue == 255:\n",
    "                    localValue = 18\n",
    "                outputFracArr [localValue, yOut,xOut] += proportion\n",
    "                \n",
    "                # like-adjacencies\n",
    "                if yAbove>=0 and landCover[yAbove,xIn] == localValue:\n",
    "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
    "                if xRight>=0 and landCover[yIn,xRight] == localValue:\n",
    "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
    "                if yBelow>=0 and landCover[yBelow,xIn] == localValue:\n",
    "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
    "                if xLeft>=0 and landCover[yIn,xLeft] == localValue:\n",
    "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
    "\n",
    "    for catNum in range (nCategories):\n",
    "        yOut = -1\n",
    "        xOut = -1\n",
    "        for yOut in range(yShapeOut): # not bothering to parallelise this, there are frac**2 fewer cells than before\n",
    "            for xOut in range(xShapeOut):\n",
    "                # like adjacencies are output as a fraction of the cells that were of a class, that\n",
    "                # have neighbours of the same class\n",
    "                if outputFracArr[catNum, yOut, xOut] > 0:\n",
    "                    outputLikeAdjArr[catNum, yOut, xOut] = (\n",
    "                        outputLikeAdjArr[catNum, yOut, xOut] / outputFracArr[catNum, yOut, xOut])\n",
    "                else:\n",
    "                    outputLikeAdjArr[catNum, yOut, xOut] = fltNDV\n",
    "                    \n",
    "                if outputFracArr[catNum, yOut, xOut] > tmpMajorityPropArr[yOut, xOut]:\n",
    "                    tmpMajorityPropArr[yOut, xOut] = outputFracArr[catNum, yOut, xOut]\n",
    "                    if catNum < 17:\n",
    "                        outputMajorityArr[yOut, xOut] = catNum\n",
    "                    elif catNum == 17:\n",
    "                        outputMajorityArr[yOut, xOut] = 254\n",
    "                    elif catNum == 18:\n",
    "                        outputMajorityArr[yOut, xOut] = 255\n",
    "\n",
    "                # output in percent (so we can use int array = smaller)\n",
    "                # it currently contains proportion of the output cell that is covered \n",
    "                # by input cells of that type, i.e. a value 0-1\n",
    "                # and since we are running with frac=10 so 100 inputs to each output, \n",
    "                # there can only be a whole percentage value\n",
    "                outputFracArr[catNum,yOut,xOut] *=100\n",
    "                # C round function won't import into cython on my machine for some reason so\n",
    "                # add 0.5 so that truncating downwards has the same effect\n",
    "                outputFracArr[catNum,yOut,xOut]+=0.5\n",
    "                \n",
    "    #return np.round(np.asarray(outputArr)).astype(np.uint8)\n",
    "    return (\n",
    "        np.asarray(outputFracArr).astype(np.uint8),\n",
    "        np.asarray(outputLikeAdjArr),\n",
    "        np.asarray(outputMajorityArr).astype(np.uint8)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def savecontResult(thing,stat, tag, data,_NDV, outDir, outName = None, decrepit=False):\n",
    "    '''\n",
    "    Save a result from the continuous raster aggregation function, using the MAP filename formats\n",
    "    '''\n",
    "    if data.dtype==np.float32 or data.dtype==np.float64:\n",
    "        gdType = gdal.GDT_Float32\n",
    "    elif data.dtype == np.int8 or data.dtype == np.uint8 or data.dtype == np.byte:\n",
    "        gdType = gdal.GDT_Byte\n",
    "    else:\n",
    "        gdType = gdal.GDT_Int32\n",
    "    \n",
    "    outDrv = gdal.GetDriverByName('GTiff')\n",
    "    if outName is None:\n",
    "        outNameTemplate = r'{0!s}\\{1!s}_5km_{2!s}{3!s}.tif'\n",
    "        outRasterName = outNameTemplate.format(outDir, thing, stat, tag)\n",
    "    else:\n",
    "        outRasterName = os.path.join(outDir, outName)\n",
    "        outRasterName = outRasterName + '.tif'\n",
    "    cOpts = [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"]\n",
    "    if decrepit:\n",
    "        cOpts = []\n",
    "    outRaster = outDrv.Create(outRasterName,data.shape[1], data.shape[0],1,gdType,\n",
    "                              cOpts)\n",
    "    outRaster.SetGeoTransform(outputGT)\n",
    "    outRaster.SetProjection(inputProj)\n",
    "    outBand = outRaster.GetRasterBand(1)\n",
    "    if _NDV:\n",
    "        outBand.SetNoDataValue(_NDV)\n",
    "    outBand.WriteArray(data)\n",
    "    outBand.FlushCache()\n",
    "    del outBand\n",
    "    outRaster = None\n",
    "\n",
    "resStructure = ('Count','Max','Mean','Min','Range','Sum','SD')\n",
    "\n",
    "\n",
    "# To enforce alignment with the mastergrids run the following on each file:\n",
    "# gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to run aggregation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define aggregation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggFactor = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDir = r'C:\\temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run for one continuous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = r'C:\\Users\\zool1301.NDPH\\Documents\\Other_Data\\GUF\\GUF28\\GUF28\\000777777786422\\0007files_aligned.tif'\n",
    "ds = gdal.Open(dataPath)\n",
    "bnd = ds.GetRasterBand(1)\n",
    "_NDV = bnd.GetNoDataValue()\n",
    "inputGT = ds.GetGeoTransform()\n",
    "inputProj = ds.GetProjection()\n",
    "inputHeightPx = ds.RasterYSize\n",
    "inputWidthPx = ds.RasterXSize\n",
    "\n",
    "inputXMin = inputGT[0]\n",
    "inputYMax = inputGT[3]\n",
    "inputXMax = inputXMin + inputGT[1] * inputWidthPx\n",
    "inputYMin = inputYMax + inputGT[5] * inputHeightPx\n",
    "inputHeightProj = inputYMax - inputYMin\n",
    "inputWidthProj = inputXMax - inputXMin\n",
    "\n",
    "desiredOutputRes = 0.008333333333333\n",
    "desiredOutputWidth = int(inputWidthProj / desiredOutputRes)\n",
    "desiredOutputHeight = int(inputHeightProj / desiredOutputRes)\n",
    "\n",
    "outputGT = (inputXMin, desiredOutputRes, 0.0, inputYMax, 0.0, -desiredOutputRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = r'C:\\Users\\zool1301\\Documents\\Other_Data\\Ferranti_Elev_15Sec\\ferranti15sec_hillshade_Illum360_scale.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(dataPath)\n",
    "bnd = ds.GetRasterBand(1)\n",
    "_NDV = bnd.GetNoDataValue()\n",
    "inputGT = ds.GetGeoTransform()\n",
    "inputProj = ds.GetProjection()\n",
    "outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-180.0, 0.041666666666665, 0.0, 90.0, 0.0, -0.041666666666665)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xLims = (21840*2,33040*2) # for 1km data\n",
    "#yLims = (9660*2,20560*2) # for 1km data\n",
    "#testArea = bnd.ReadAsArray(xLims[0],yLims[0],xLims[1]-xLims[0],yLims[1]-yLims[0])\n",
    "allData = bnd.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData[np.isnan(allData)] = _NDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data shape must be a clean muliple of aggregation factor, here we just fudge by cutting the end off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData = allData[0:-1, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputGT2 = (-180.0, 0.008333333333333, 0.0, 90.0, 0.0, -0.008333333333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If we are short of memory do we need mean and sd? (if so we'll have to tile: not yet implemented)\n",
    "SkipMeanAndSD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = aggregateContinuous(allData.astype(np.float32), aggFactor, _NDV, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save all as compressed or uncompressed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resStructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncompressed\n",
    "for i in range(len(resStructure)):\n",
    "    stat = resStructure[i]\n",
    "    savecontResult(thing,stat,'',res[i],_NDV, outDir, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or compressed\n",
    "for i in range(len(resStructure)):\n",
    "    stat = resStructure[i]\n",
    "    savecontResult(thing,stat,'_LZW',res[i],_NDV, outDir, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or save manually if we've skipped mean / sd\n",
    "savecontResult('HS360Deg_1k','Count','',res[0],_NDV, outDir, False)\n",
    "savecontResult('HS360Deg_1k','Max','',res[1],_NDV, outDir, False)\n",
    "savecontResult('HS360Deg_1k','Min','',res[3],_NDV, outDir, False)\n",
    "savecontResult('HS360Deg_1k','Range','',res[4],_NDV, outDir, False)\n",
    "savecontResult('HS360Deg_1k','Sum','',res[5],_NDV, outDir, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run for multiple continuous datasets with different names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPaths = {\n",
    "'EVI_Mean': r'G:\\NewStats\\MG_Aligned\\EVI_Mean_From_Monthly.tif',\n",
    "'LST_Day_Mean': r'G:\\NewStats\\MG_Aligned\\LST_Day_Mean_From_Monthly.tif',\n",
    "'LST_Night_Mean': r'G:\\NewStats\\MG_Aligned\\LST_Night_Mean_From_Monthly.tif',\n",
    "'TCW_Mean': r'G:\\NewStats\\MG_Aligned\\TCW_Mean_From_Monthly.tif',\n",
    "'TCB_Mean': r'G:\\NewStats\\MG_Aligned\\TCB_Mean_From_Monthly.tif',\n",
    "\n",
    "'EVI_SD': r'G:\\NewStats\\MG_Aligned\\EVI_SD_From_Daily.tif',\n",
    "'LST_Day_SD': r'G:\\NewStats\\MG_Aligned\\LST_Day_SD_From_Daily.tif',\n",
    "'LST_Night_SD': r'G:\\NewStats\\MG_Aligned\\LST_Night_SD_From_Daily.tif',\n",
    "'TCW_SD': r'G:\\NewStats\\MG_Aligned\\TCW_SD_From_Daily.tif',\n",
    "'TCB_SD': r'G:\\NewStats\\MG_Aligned\\TCB_SD_From_Daily.tif',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDir = r'G:\\SynopticData\\MG_Aligned\\5km\\tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for thing in dataPaths:\n",
    "    ds = gdal.Open(dataPaths[thing])\n",
    "    bnd = ds.GetRasterBand(1)\n",
    "    _NDV = bnd.GetNoDataValue()\n",
    "    inputGT = ds.GetGeoTransform()\n",
    "    inputProj = ds.GetProjection()\n",
    "    outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)\n",
    "    print ds.GetDescription()\n",
    "    allData = bnd.ReadAsArray()\n",
    "    allData[np.isnan(allData)] = _NDV\n",
    "    res = aggregateContinuous(allData, aggFactor, _NDV)\n",
    "    for i in range (len(resStructure)):\n",
    "        stat = resStructure[i]\n",
    "        savecontResult(thing,stat,'',res[i],_NDV, outDir, None, True)\n",
    "        savecontResult(thing,stat,'_LZW',res[i],_NDV, outDir, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPaths = glob.glob(r'C:\\Temp\\dataprep\\test_invert_arid.tif')\n",
    "ds = gdal.Open(dataPaths[0])\n",
    "b = ds.GetRasterBand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43200, 17400)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.RasterXSize, ds.RasterYSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-128.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.GetNoDataValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#self, xSizeIn, ySizeIn, xSizeOut, ySizeOut, _NDV, minMaxRangeSumOnly)\n",
    "aggomat = RasterAggregator_float(43200,17400,8640,3480,-128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = b.ReadAsArray(0,0,21600,8700).astype(np.float32)\n",
    "#(self, float[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "aggomat.addTile(arr1, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = b.ReadAsArray(21600,0,21600,8700).astype(np.float32)\n",
    "#(self, float[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "aggomat.addTile(arr1, 21600, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = b.ReadAsArray(0,8700,21600,8700).astype(np.float32)\n",
    "#(self, float[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "aggomat.addTile(arr1, 0, 8700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = b.ReadAsArray(21600,8700,21600,8700).astype(np.float32)\n",
    "#(self, float[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "aggomat.addTile(arr1, 21600, 8700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = aggomat.GetResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3480L, 8640L)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['count'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run for multiple continuous datasets in a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for example some output monthly data cubes at 1km\n",
    "#dataPaths = glob.glob(r'G:\\Extra\\Output\\Aggregated\\1km\\LST*.tif')\n",
    "#dataPaths = glob.glob(r'G:\\DataPrep\\population\\GRUMP\\tif\\GRUMP*.tif')\n",
    "#dataPaths = glob.glob(r'F:\\MOD11A2_Gapfilled_Output\\LST_Day\\Output_Final_30k_2030pc\\*Data.tif')\n",
    "#dataPaths = glob.glob(r'F:\\MOD11A2_Input_Mosaics\\Day\\*_Day.tif')\n",
    "dataPaths = glob.glob(r'E:\\Temp\\pop\\ihme_figures\\02_processing\\06_IHME_Corrected_Grids\\by_gender\\*.tif')\n",
    "#dataPaths = glob.glob(r'E:\\Temp\\pop\\ihme_figures\\04_outputs\\ihme_pop_clipped_2016_limits\\*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = '.'.join(os.path.basename(dataPaths[0]).split(os.path.extsep)[:-1])\n",
    "fn = fn.replace('.1km.Data', '.5km.Mean')\n",
    "fn = fn.replace('1km', '5km')\n",
    "fn = fn + '_5km'\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#outDir = r'G:\\Extra\\Output\\Aggregated\\5km'\n",
    "outDir = r'G:\\DataPrep\\population\\GRUMP\\tif'\n",
    "outDir = r'\\\\map-fs1.ndph.ox.ac.uk\\map_data\\hsg\\MODIS_Data\\5km_8day\\LST_Day'\n",
    "outDir = r'\\\\map-fs1.ndph.ox.ac.uk\\map_data\\hsg\\MODIS_Data\\5km_8day_Unfilled\\LST_Day'\n",
    "outDir = r'E:\\Temp\\pop\\ihme_figures\\04_outputs\\ihme_pop_clipped_2016_limits\\5k_sum'\n",
    "outDir = r'E:\\Temp\\pop\\ihme_figures\\02_processing\\06_IHME_Corrected_Grids\\by_gender\\5km_sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we are saving only the mean grid from the aggregation stats, which is all that's kept for the 5km cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outDir):\n",
    "    os.makedirs(outDir)\n",
    "for filename1k in dataPaths:\n",
    "    ds = gdal.Open(filename1k)\n",
    "    bnd = ds.GetRasterBand(1)\n",
    "    _NDV = bnd.GetNoDataValue()\n",
    "    \n",
    "    inputGT = ds.GetGeoTransform()\n",
    "    inputProj = ds.GetProjection()\n",
    "    outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)\n",
    "    print ds.GetDescription()\n",
    "    allData = bnd.ReadAsArray()\n",
    "    \n",
    "    dTypeIn = allData.dtype\n",
    "    if dTypeIn != np.float32:\n",
    "        allData = allData.astype(np.float32)\n",
    "        dTypeChanged = True\n",
    "    else:\n",
    "        dTypeChanged = False\n",
    "    \n",
    "    if _NDV:\n",
    "        allData[np.isnan(allData)] = _NDV\n",
    "        res = aggregateContinuous(allData, aggFactor, _NDV)\n",
    "    else:\n",
    "        res = aggregateContinuous(allData, aggFactor)\n",
    "    resMean = res[\"mean\"]\n",
    "    resMin = res[\"min\"]\n",
    "    resMax = res[\"max\"]\n",
    "    if dTypeChanged:\n",
    "        resMean = resMean.astype(dTypeIn)\n",
    "        resMin = resMin.astype(dTypeIn)\n",
    "        resMax = resMax.astype(dTypeIn)\n",
    "    \n",
    "    outFNStub = os.path.extsep.join(os.path.basename(filename1k).split(os.path.extsep)[:-1])\n",
    "    outFNStub = outFNStub.replace('.1km.Data', '.5km.Mean')\n",
    "    outFNStub = outFNStub.replace('1km', '5km')\n",
    "    outFNBase = outFNStub + \"_5km_Unfilled_Mean\"\n",
    "    #fn = fn + '_5km_Unfilled\n",
    "    #savecontResult('', '', '', resMean, _NDV, outDir, outFNBase, False)\n",
    "    outFNBase = outFNStub + \"_5km_Max\"\n",
    "    savecontResult('', '', '', resMax, _NDV, outDir, outFNBase, False)\n",
    "    outFNBase = outFNStub + \"_5km_Min\"\n",
    "    savecontResult('', '', '', resMin, _NDV, outDir, outFNBase, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outDir):\n",
    "    os.makedirs(outDir)\n",
    "for filename1k in dataPaths:\n",
    "    ds = gdal.Open(filename1k)\n",
    "    bnd = ds.GetRasterBand(1)\n",
    "    _NDV = bnd.GetNoDataValue()\n",
    "    \n",
    "    inputGT = ds.GetGeoTransform()\n",
    "    inputProj = ds.GetProjection()\n",
    "    outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)\n",
    "    print ds.GetDescription()\n",
    "    allData = bnd.ReadAsArray()\n",
    "    \n",
    "    dTypeIn = allData.dtype\n",
    "    if dTypeIn != np.float32:\n",
    "        allData = allData.astype(np.float32)\n",
    "        dTypeChanged = True\n",
    "    else:\n",
    "        dTypeChanged = False\n",
    "    \n",
    "    if _NDV:\n",
    "        allData[np.isnan(allData)] = _NDV\n",
    "        #res = aggregateContinuous(allData, aggFactor, _NDV)\n",
    "        res = aggregateContinuous(allData, aggFactor, _NDV,  minMaxRangeSumOnly = 1)\n",
    "    else:\n",
    "        res = aggregateContinuous(allData, aggFactor, None, minMaxRangeSumOnly = 1)\n",
    "    resSum = res[\"sum\"]\n",
    "    if dTypeChanged:\n",
    "        resSum = resSum.astype(dTypeIn)\n",
    "        \n",
    "    outFNStub = os.path.extsep.join(os.path.basename(filename1k).split(os.path.extsep)[:-1])\n",
    "    outFNStub = outFNStub.replace('.1km.Data', '.5km.Mean')\n",
    "    outFNStub = outFNStub.replace('1km', '5km')\n",
    "    outFNBase = outFNStub + \"_5km_Sum\"\n",
    "    #fn = fn + '_5km_Unfilled\n",
    "    savecontResult('', '', '', resSum, _NDV, outDir, outFNBase, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run for a single categorical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide category numbers (raster values) and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The values that the input raster has, which should start from zero\n",
    "ibgpCats = {\n",
    "    0:'Water',\n",
    "    1:'Evergreen_Needleleaf_Forest',\n",
    "    2:'Evergreen_Broadleaf_Forest',\n",
    "    3:'Deciduous_Needleleaf_Forest',\n",
    "    4:'Deciduous_Broadleaf_Forest',\n",
    "    5:'Mixed_Forest',\n",
    "    6:'Closed_Shrublands',\n",
    "    7:'Open_Shrublands',\n",
    "    8:'Woody_Savannas',\n",
    "    9:'Savannas',\n",
    "    10:'Grasslands',\n",
    "    11:'Permanent_Wetlands',\n",
    "    12:'Croplands',\n",
    "    13:'Urban_And_Built_Up',\n",
    "    14:'Cropland_Natural_Vegetation_Mosaic',\n",
    "    15:'Snow_And_Ice',\n",
    "    16:'Barren_Or_Sparsely_Populated',\n",
    "    17:'Unclassified', # =254 in source data, hardcoded a remap in the cython\n",
    "    18:'No_Data' # =255 in source data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ibgpCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nCats = len(ibgpCats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# global calculation takes approx 16 seconds\n",
    "res = aggregateStats(allData,10,len(ibgpCats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write categorical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the results to individual (one per class) tiff files\n",
    "outDrv = gdal.GetDriverByName('GTiff')\n",
    "outNameTemplate = r'G:\\MCD12Q1\\Proportional\\5km\\{0!s}_{1!s}_5km_{2!s}.tif'\n",
    "for i in range(0,len(ibgpCats)):\n",
    "    className = ibgpCats[i]\n",
    "    outRasterName = outNameTemplate.format(i,className,\"Percentage\")\n",
    "    outRaster = outDrv.Create(outRasterName,res[0].shape[2], res[0].shape[1],1,gdal.GDT_Byte,\n",
    "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "    outRaster.SetGeoTransform(outputGT)\n",
    "    outRaster.SetProjection(inputProj)\n",
    "    outBand = outRaster.GetRasterBand(1)\n",
    "    outBand.WriteArray(res[0][i])\n",
    "    outBand.FlushCache()\n",
    "    del outBand\n",
    "    outRasterName = outNameTemplate.format(i,className,\"LikeAdjacencies\")\n",
    "    outRaster = outDrv.Create(outRasterName,res[1].shape[2], res[1].shape[1],1,gdal.GDT_Float32,\n",
    "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "    outRaster.SetGeoTransform(outputGT)\n",
    "    outRaster.SetProjection(inputProj)\n",
    "    outBand = outRaster.GetRasterBand(1)\n",
    "    outBand.WriteArray(res[1][i])\n",
    "    outBand.FlushCache()\n",
    "    del outBand\n",
    "    outRaster = None\n",
    "outRasterName = outNameTemplate.format(\"Overall\", \"Class\", \"Majority\")\n",
    "outRaster = outDrv.Create(outRasterName,res[2].shape[1], res[2].shape[0],\n",
    "                          1,gdal.GDT_Byte,\n",
    "                          [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\n",
    "                           \"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "outRaster.SetGeoTransform(outputGT)\n",
    "outRaster.SetProjection(inputProj)\n",
    "outBand = outRaster.GetRasterBand(1)\n",
    "outBand.WriteArray(res[2])\n",
    "outBand.FlushCache()\n",
    "del outBand\n",
    "outRaster = None\n",
    "# To enforce alignment with the mastergrids run the following on each file:\n",
    "# gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run for multiple categorical datasets in a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPaths = glob.glob(r'G:\\MCD12Q1\\500m\\A2013*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A2013001_MCD12Q1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = os.path.basename(dataPaths[0]).split(os.path.extsep)[0]\n",
    "fn = fn.replace('_1km_Data', '.5km.Mean')\n",
    "fn = fn.replace('_1km_FilledProportion', '.5km.FilledProportion')\n",
    "fn = fn.replace('Night_', 'Night.')\n",
    "fn = fn.replace('-', '.')\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDir = r'G:\\MCD12Q1\\5km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggFactor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(dataPaths[0])\n",
    "bnd = ds.GetRasterBand(1)\n",
    "_NDV = bnd.GetNoDataValue()\n",
    "inputGT = ds.GetGeoTransform()\n",
    "inputProj = ds.GetProjection()\n",
    "ds = None\n",
    "outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the results to individual (one per class) tiff files\n",
    "for filename500m in dataPaths:\n",
    "    inFN = os.path.basename(filename500m).split(os.path.extsep)[0]\n",
    "    yr = inFN[1:5]\n",
    "    outDrv = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    outNameTemplate = r'{0!s}\\{1!s}\\{2!s}.{3!s}_{4!s}.5km.{5!s}.tif'\n",
    "    \n",
    "    likeAdjNDV = -9999\n",
    "    with rasterio.open(filename500m) as src:\n",
    "        allData = src.read_band(1, masked=False)\n",
    "    res = aggregateStats(allData,aggFactor,len(ibgpCats), likeAdjNDV)\n",
    "    \n",
    "    for i in range(0,len(ibgpCats)):\n",
    "        className = ibgpCats[i]\n",
    "        outRasterName = outNameTemplate.format(\n",
    "            outDir, \n",
    "            \"Proportional\", \n",
    "            yr,\n",
    "            \"Class\"+str(i).zfill(2), \n",
    "            className, \n",
    "            \"Percentage\"\n",
    "        )\n",
    "        outRaster = outDrv.Create(outRasterName,res[0].shape[2], res[0].shape[1],1,gdal.GDT_Byte,\n",
    "                                  [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "        outRaster.SetGeoTransform(outputGT)\n",
    "        outRaster.SetProjection(inputProj)\n",
    "        outBand = outRaster.GetRasterBand(1)\n",
    "        outBand.WriteArray(res[0][i])\n",
    "        outBand.FlushCache()\n",
    "        del outBand\n",
    "        \n",
    "        #outRasterName = outNameTemplate.format(outDir, i, className, \"LikeAdjacencies\")\n",
    "        outRasterName = outNameTemplate.format(\n",
    "            outDir, \n",
    "            \"LikeAdjacencies\", \n",
    "            yr,\n",
    "            \"Class\"+str(i).zfill(2), \n",
    "            className, \n",
    "            \"LikeAdjacencies\"\n",
    "        )\n",
    "        outRaster = outDrv.Create(outRasterName,res[1].shape[2], res[1].shape[1],1,gdal.GDT_Float32,\n",
    "                                  [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "        outRaster.SetGeoTransform(outputGT)\n",
    "        outRaster.SetProjection(inputProj)\n",
    "        outBand = outRaster.GetRasterBand(1)\n",
    "        outBand.SetNoDataValue(likeAdjNDV)\n",
    "        outBand.WriteArray(res[1][i])\n",
    "        outBand.FlushCache()\n",
    "        del outBand\n",
    "        outRaster = None\n",
    "        \n",
    "    #outRasterName = outNameTemplate.format(\"Overall\", \"Class\", \"Majority\")\n",
    "    outRasterName = outNameTemplate.format(\n",
    "            outDir, \n",
    "            \"Majority\", \n",
    "            yr,\n",
    "            \"Overall\", \n",
    "            \"Class\", \n",
    "            \"Majority\"\n",
    "        )\n",
    "    outRaster = outDrv.Create(outRasterName,res[2].shape[1], res[2].shape[0],\n",
    "                              1,gdal.GDT_Byte,\n",
    "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\n",
    "                               \"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
    "    outRaster.SetGeoTransform(outputGT)\n",
    "    outRaster.SetProjection(inputProj)\n",
    "    outBand = outRaster.GetRasterBand(1)\n",
    "    outBand.WriteArray(res[2])\n",
    "    outBand.FlushCache()\n",
    "    del outBand\n",
    "    outRaster = None\n",
    "    # To enforce alignment with the mastergrids run the following on each file:\n",
    "    # gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:148:37: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:149:37: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:159:38: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:168:31: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:172:31: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:176:31: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:180:31: Use boundscheck(False) for faster access\n",
      "warning: C:\\Users\\zool1301.NDPH\\.ipython\\cython\\_cython_magic_6f8e3c1b57ad952cd2bd71cd93ede119.pyx:183:41: Use boundscheck(False) for faster access\n"
     ]
    }
   ],
   "source": [
    "%%cython --compile-args=/openmp --link-args=/openmp --force\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport openmp\n",
    "from cython.parallel import parallel, prange\n",
    "\n",
    "cdef class RasterAggregator_Categorical:\n",
    "    ''' Aggregates a categorical raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
    "\n",
    "     Returns a tuple containing two three dimensional grids and one two dimensional grid\n",
    "     at the aggregated resolution, each representing a different summary of the source\n",
    "     pixels covered by each output pixel, namely:\n",
    "        (\n",
    "          Fraction (3D),\n",
    "          Like-Adjacency (3D),\n",
    "          Majority (2D)\n",
    "        )\n",
    "     The fraction and like adjacency outputs have one image (in the z dimension) for each category\n",
    "     (value) of the input raster. It's assumed that the input has values from zero and the mapping\n",
    "     is therefore between the input value and the output position, i.e. an input pixel of value 4\n",
    "     will contribute to the 4th grid in the output stack. This is suitable for use with IGBP\n",
    "     landcover data.\n",
    "\n",
    "     Note that this means the output will have as many \"layers\" in the z dimension as there are unique\n",
    "     values in the input data. Thus this is only recommended where there are a small number of unique\n",
    "     values, or the output grids are small, due to the large memory implications.\n",
    "\n",
    "     The input grid must (in this implementation) have dimensions that are\n",
    "     exact multiples of aggregation factor. The input grid must be of unsigned integer type.\n",
    "    '''\n",
    "\n",
    "    cdef:\n",
    "       Py_ssize_t xShapeIn, yShapeIn, tileXShapeIn, tileYShapeIn\n",
    "       Py_ssize_t xShapeOut, yShapeOut\n",
    "       double xFact, yFact\n",
    "       float proportion\n",
    "\n",
    "    cdef:\n",
    "        Py_ssize_t xIn, yIn, xOut, yOut, catNum\n",
    "        int yBelow, yAbove, xLeft, xRight\n",
    "\n",
    "\n",
    "    cdef:\n",
    "        unsigned char nCategories, _NDV\n",
    "        float[:,:,::1] outputFracArr\n",
    "        float[:,:,::1] outputLikeAdjArr\n",
    "        unsigned char [:,::1] outputMajorityArr\n",
    "\n",
    "    cdef:\n",
    "        float [:,::1] tmpMajorityPropArr\n",
    "        char[:,::1] _coverageArr\n",
    "\n",
    "    def __cinit__(self, xSizeIn, ySizeIn, xSizeOut, ySizeOut, unsigned char nCategories, _NDV):\n",
    "        assert xSizeIn > xSizeOut\n",
    "        assert ySizeIn > ySizeOut\n",
    "\n",
    "        self.xShapeIn = xSizeIn\n",
    "        self.yShapeIn = ySizeIn\n",
    "        self.xShapeOut = xSizeOut\n",
    "        self.yShapeOut = ySizeOut\n",
    "\n",
    "        self.xFact = <double>self.xShapeIn / self.xShapeOut\n",
    "        self.yFact = <double>self.yShapeIn / self.yShapeOut\n",
    "\n",
    "        self._NDV = _NDV\n",
    "        self.nCategories = nCategories\n",
    "\n",
    "        self.outputFracArr = np.zeros(shape = (nCategories, self.yShapeOut, self.xShapeOut),\n",
    "                                      dtype = np.float32)\n",
    "        self.outputLikeAdjArr = np.zeros(shape = (nCategories, self.yShapeOut, self.xShapeOut),\n",
    "                                         dtype = np.float32)\n",
    "        self.outputMajorityArr = np.zeros(shape = (self.yShapeOut, self.xShapeOut),\n",
    "                                          dtype = np.uint8)\n",
    "        self.tmpMajorityPropArr = np.zeros(shape = (self.yShapeOut, self.xShapeOut),\n",
    "                                           dtype = np.float32)\n",
    "        self._coverageArr = np.zeros(shape = (self.yShapeOut, self.xShapeOut), dtype = np.byte)\n",
    "\n",
    "    cpdef addTile(self, unsigned char[:,::1] data, Py_ssize_t xOffset, Py_ssize_t yOffset):\n",
    "        cdef:\n",
    "            #shape of the data we receive\n",
    "            Py_ssize_t tileYShapeIn, tileXShapeIn\n",
    "            # coords of neighbours in global grid\n",
    "            int yBelowGlobal, yAboveGlobal, xLeftGlobal, xRightGlobal\n",
    "            # coords of neighbours in the received tile\n",
    "            int yBelowTile, yAboveTile, xLeftTile, xRightTile\n",
    "            # current pixel coords in global and tile coords\n",
    "            Py_ssize_t xInGlobal, xInTile, yInGlobal, yInTile\n",
    "            unsigned char localValue\n",
    "            unsigned char nNeighbours\n",
    "            unsigned char catNum\n",
    "            float likeAdjProp\n",
    "            Py_ssize_t xOut, yOut\n",
    "            # how much of an output cell does each input cell account for\n",
    "            float proportion\n",
    "            char isOk = 1\n",
    "\n",
    "        tileXShapeIn = data.shape[1]\n",
    "        tileYShapeIn = data.shape[0]\n",
    "\n",
    "        # how much of an output cell does each input cell account for\n",
    "        proportion = 1.0 / (self.xFact * self.yFact)\n",
    "\n",
    "\n",
    "        with nogil, parallel():\n",
    "            for yInTile in prange (tileYShapeIn):\n",
    "                yInGlobal = yInTile + yOffset\n",
    "\n",
    "                yAboveGlobal = yInGlobal - 1\n",
    "                if yInGlobal == 0:\n",
    "                    yAboveGlobal = -1\n",
    "                yAboveTile = yInTile - 1\n",
    "                if yInTile == 0:\n",
    "                    yAboveTile = -1\n",
    "\n",
    "                yBelowGlobal = yInGlobal + 1\n",
    "                if yInGlobal == self.yShapeIn - 1:\n",
    "                    yBelowGlobal = -1\n",
    "                yBelowTile = yInTile + 1\n",
    "                if yInTile == tileYShapeIn - 1:\n",
    "                    yBelowTile = -1\n",
    "\n",
    "                yOut = <int> (yInGlobal / self.yFact)\n",
    "                # yeah i know that it's an unsigned char but we won't actually use this value,\n",
    "                # these assignments are to cause the cython converter to make these thread-local\n",
    "                localValue = -1\n",
    "                xOut = -1\n",
    "\n",
    "                for xInTile in range(tileXShapeIn):\n",
    "                    xInGlobal = xInTile + xOffset\n",
    "                    nNeighbours = 0\n",
    "                    likeAdjProp = 0\n",
    "\n",
    "                    xLeftGlobal = xInGlobal - 1\n",
    "                    if xInGlobal == 0:\n",
    "                        xLeftGlobal = -1\n",
    "                    xLeftTile = xInTile - 1\n",
    "                    if xInTile == 0:\n",
    "                        xLeftTile = -1\n",
    "\n",
    "                    xRightGlobal = xInGlobal + 1\n",
    "                    if xInGlobal == self.xShapeIn - 1:\n",
    "                        xRightGlobal = -1\n",
    "                    xRightTile = xInTile + 1\n",
    "                    if xInTile == tileXShapeIn - 1:\n",
    "                        xRightTile = -1\n",
    "\n",
    "                    xOut = <int> (xInGlobal / self.xFact)\n",
    "\n",
    "                    self._coverageArr[yOut, xOut] = 1\n",
    "                    localValue = data[yInTile, xInTile]\n",
    "                    if localValue == self._NDV:\n",
    "                        # don't do anything\n",
    "                        continue\n",
    "                    if localValue > self.nCategories + 1:\n",
    "                        isOk = 0\n",
    "                        break\n",
    "\n",
    "                    # the fraction is straightforward, just the proportion of the output cell\n",
    "                    # covered by this one\n",
    "                    self.outputFracArr[localValue, yOut, xOut] += proportion\n",
    "\n",
    "                    # the like adjacency contribution of a given incoming cell\n",
    "                    # is less straightforward because it depends on neighbours and at\n",
    "                    # edges of a tile we don't have access to all neighbours of incoming data\n",
    "                    # so we just calculate it based on how many neighbours we do have\n",
    "                    # (this isn't totally accurate of course)\n",
    "                    if yAboveTile >= 0:\n",
    "                        nNeighbours += 1\n",
    "                        if data[yAboveTile, xInTile] == localValue:\n",
    "                            likeAdjProp += 1\n",
    "                    if xRightTile >= 0:\n",
    "                        nNeighbours += 1\n",
    "                        if data[yInTile, xRightTile] == localValue:\n",
    "                            likeAdjProp += 1\n",
    "                    if yBelowTile >= 0:\n",
    "                        nNeighbours += 1\n",
    "                        if data[yBelowTile, xInTile] == localValue:\n",
    "                            likeAdjProp += 1\n",
    "                    if xLeftTile >= 0:\n",
    "                        nNeighbours += 1\n",
    "                        if data[yInTile, xLeftTile] == localValue:\n",
    "                            likeAdjProp += 1\n",
    "                    #likeAdjProp = likeAdjProp / nNeighbours\n",
    "                    self.outputLikeAdjArr[localValue, yOut, xOut] += (\n",
    "                        (likeAdjProp / nNeighbours) * proportion)\n",
    "        if not isOk:\n",
    "            print \"A value was encountered that was greater than the number of categories expected\"\n",
    "        \n",
    "\n",
    "    cdef finalise(self):\n",
    "        cdef:\n",
    "            Py_ssize_t xOut, yOut\n",
    "            float iscomplete = 1\n",
    "        for catNum in range (self.nCategories):\n",
    "            yOut = -1\n",
    "            xOut = -1\n",
    "            for yOut in range (self.yShapeOut):\n",
    "                xOut = -1\n",
    "                for xOut in range (self.xShapeOut):\n",
    "                    if self._coverageArrArr[yOut, xOut] == 0:\n",
    "                        iscomplete = 0\n",
    "                    if self.outputFracArr[catNum, yOut, xOut] > 0:\n",
    "                        self.outputLikeAdjArr[catNum, yOut, xOut] = (\n",
    "                            self.outputLikeAdjArr[catNum, yOut, xOut] / self.outputFracArr[catNum, yOut, xOut]\n",
    "                        )\n",
    "                    else:\n",
    "                        self.outputLikeAdjArr[catNum, yOut, xOut] = self._NDV\n",
    "\n",
    "                    if self.outputFracArr[catNum, yOut, xOut] > self.tmpMajorityPropArr[yOut, xOut]:\n",
    "                        self.tmpMajorityPropArr[yOut, xOut] = self.outputFracArr[catNum, yOut, xOut]\n",
    "                        self.outputMajorityArr[yOut, xOut] = catNum\n",
    "\n",
    "                    self.outputFracArr[catNum, yOut, xOut] *= 100\n",
    "                    self.outputFracArr[catNum, yOut, xOut] += 0.5\n",
    "\n",
    "        if not iscomplete:\n",
    "            print \"Warning, generating a result without having received input data for full extent\"\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    cpdef GetResults(self):\n",
    "        '''If input is complete, returns an object containing 'fractions', 'likeadjacencies', 'majority' '''\n",
    "        if not self.finalise():\n",
    "            return None\n",
    "        return {\n",
    "            \"fractions\": np.asarray(self.outputFracArr).astype(np.uint8),\n",
    "            \"likeadjacencies\": np.asarray(self.outputLikeAdjArr),\n",
    "            \"majority\": np.asarray(self.outputMajorityArr) #.astype(np.uint8)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def catRunner(dataPaths, categories):\n",
    "    '''Run the aggregation code for each file specifed in dataPaths which should be a list of tiff files.\n",
    "    \n",
    "    The global notebook variables outDir, method, minMaxRangeSumOnly, itemsToSave, and \n",
    "    (aggregationFactor OR resolution OR requiredXSize and requiredYSize)\n",
    "    should be set first, along with the fnGetter function for producing output filenames.\n",
    "    '''\n",
    "    for f in dataPaths:\n",
    "        print f\n",
    "        ds = gdal.Open(f)\n",
    "        b = ds.GetRasterBand(1)\n",
    "        ndv = b.GetNoDataValue()\n",
    "        if ndv is None:\n",
    "            print \"no ndv\"\n",
    "            ndv = -9999\n",
    "        inputGT = ds.GetGeoTransform()\n",
    "        inputProj = ds.GetProjection()\n",
    "        \n",
    "        assert len(categories) <= 256\n",
    "        assert max(categories) < 256\n",
    "        assert min(categories) >= 0\n",
    "        \n",
    "        nCategories = len(categories)\n",
    "        \n",
    "        nBytesRequired = ds.RasterXSize * ds.RasterYSize * 1 * nCategories\n",
    "\n",
    "        outGT, outShape = calcAggregatedProperties(method, (ds.RasterYSize, ds.RasterXSize), \n",
    "                                                   inputGT, aggregationFactor, \n",
    "                                                   (requiredYSize, requiredXSize), \n",
    "                                                   resolution)\n",
    "        outYSize, outXSize = outShape    \n",
    "        tiles = getTiles(ds.RasterXSize, ds.RasterYSize, 20000)\n",
    "        \n",
    "        aggregator = RasterAggregator_Categorical(ds.RasterXSize, ds.RasterYSize, \n",
    "                                            outXSize, outYSize,float(ndv), \n",
    "                                            minMaxRangeSumOnly)\n",
    "        print \"Running {0!s} tiles\".format(len(tiles)),\n",
    "        for tile in tiles:\n",
    "            print \".\",\n",
    "            xoff = tile[0][0]\n",
    "            yoff = tile[1][0]\n",
    "            xsize = tile[0][1] - xoff\n",
    "            ysize = tile[1][1] - yoff\n",
    "            inArr = b.ReadAsArray(xoff, yoff, xsize, ysize).astype(np.uint8)\n",
    "            aggregator.addTile(inArr, xoff, yoff)\n",
    "        r = aggregator.GetResults()\n",
    "        itemstosave = ['fractions','likeadjacencies','majority']\n",
    "        for i in itemstosave:\n",
    "            fnOut = fnGetter(os.path.basename(f), i)\n",
    "            print fnOut\n",
    "            # the file-saving function will save to a tiff of datatype matching the array\n",
    "            # it receives.\n",
    "            if i in ['fractions','max','range']:\n",
    "                # if the input was some integer type then save as this, even though the \n",
    "                # aggregation code always outputs float32\n",
    "                nptype = gdal_array.GDALTypeCodeToNumericTypeCode(b.DataType)\n",
    "                savecontResult(r[i].astype(nptype), ndv, outGT, inputProj, outDir, fnOut)\n",
    "            elif i in ['mean','sd', 'sum']:\n",
    "                # sum might be integer but potentially of larger type than the input, don't bother\n",
    "                # dealing with conversion for now\n",
    "                savecontResult(r[i], ndv, outGT, inputProj, outDir, fnOut)\n",
    "            elif i in ['count']:\n",
    "                savecontResult(r[i].astype(np.int32), ndv, outGT, inputProj, outDir, fnOut)\n",
    "            else:\n",
    "                assert False\n",
    "                \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
