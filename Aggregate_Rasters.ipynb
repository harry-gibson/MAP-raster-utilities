{
 "metadata": {
  "name": "",
  "signature": "sha256:373565565c1312468e9264469904700ede5b93086a61b7195d9345c71c648379"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from osgeo import gdal\n",
      "import numpy as np\n",
      "import scipy.ndimage as ndi\n",
      "%load_ext cython\n",
      "import glob\n",
      "import os\n",
      "import rasterio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Aggregation functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "%%cython --compile-args=/openmp --link-args=/openmp --force\n",
      "cimport cython\n",
      "import numpy as np\n",
      "cimport openmp\n",
      "from cython.parallel import parallel, prange\n",
      "from libc.math cimport sqrt\n",
      "\n",
      "@cython.boundscheck(False)\n",
      "@cython.cdivision(True)\n",
      "@cython.wraparound(False)\n",
      "cpdef aggregateContinuous(float [:,::1] data, int fact, float _NDV = np.inf, char minMaxRangeSumOnly = 0):\n",
      "''' Aggregates a continuous raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
      " \n",
      " Returns a tuple containing up to seven grids at the aggregated resolution, \n",
      " each representing a different summary of the source pixels covered by each output\n",
      " pixel, namely:\n",
      "    (\n",
      "      Count, \n",
      "      Max, \n",
      "      Mean (or None), \n",
      "      Min, \n",
      "      Range, \n",
      "      Sum, \n",
      "      SD (or None)\n",
      "    )\n",
      " The input grid must (in this implementation) have dimensions that are \n",
      " exact multiples of aggregation factor.\n",
      "'''    \n",
      "    cdef:\n",
      "        Py_ssize_t xShapeIn, yShapeIn, xShapeOut, yShapeOut\n",
      "        Py_ssize_t xIn, yIn, xOut, yOut, catNum\n",
      "        int yBelow, yAbove, xLeft, xRight\n",
      "        float localValue\n",
      "        float[:,::1] outputMeanArr\n",
      "        float[:,::1] outputMinArr\n",
      "        float[:,::1] outputMaxArr\n",
      "        float[:,::1] outputRangeArr\n",
      "        float[:,::1] outputSumArr\n",
      "        float[:,::1] outputSDArr\n",
      "        \n",
      "        float[:,::1] _oldSDArr\n",
      "        float[:,::1] _oldMeanArr\n",
      "        \n",
      "        int[:,::1] outputCountArr\n",
      "        float proportion\n",
      "        double variance\n",
      "        \n",
      "    yShapeIn = data.shape[0]\n",
      "    xShapeIn = data.shape[1]\n",
      "    \n",
      "    assert fact > 0\n",
      "    assert yShapeIn % fact == 0\n",
      "    assert xShapeIn % fact == 0\n",
      "    \n",
      "    # how much of an output cell does each input cell account for\n",
      "    proportion = 1.0 / (fact**2)\n",
      "    \n",
      "    yShapeOut = yShapeIn / fact\n",
      "    xShapeOut = xShapeIn / fact\n",
      "    \n",
      "    outputMinArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    outputMaxArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    \n",
      "    if not minMaxRangeSumOnly:\n",
      "        outputMeanArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "        outputSDArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    \n",
      "        _oldSDArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "        _oldMeanArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "        \n",
      "        outputMeanArr[:] = _NDV\n",
      "        outputSDArr[:] = _NDV\n",
      "    \n",
      "        _oldMeanArr[:] = _NDV\n",
      "        _oldSDArr[:] = _NDV\n",
      "    \n",
      "    \n",
      "    outputMinArr[:] = np.inf\n",
      "    outputMaxArr[:] = -np.inf\n",
      "    \n",
      "    outputSumArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    outputRangeArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    outputCountArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.int32)\n",
      "    \n",
      "    #with nogil, parallel():\n",
      "    # no parallel written this way round as the min/max values would be non deterministic\n",
      "    if 1:\n",
      "        #yOut = -1\n",
      "        #xOut = -1\n",
      "        #localValue = -1\n",
      "        for yIn in range(yShapeIn):\n",
      "            yAbove = yIn - 1\n",
      "            if yIn == 0:\n",
      "                yAbove = -1\n",
      "            yBelow = yIn+1\n",
      "            if yIn == yShapeIn-1:\n",
      "                yBelow = -1\n",
      "            yOut = <int> yIn / fact\n",
      "            localValue=-1\n",
      "            xOut = -1\n",
      "            for xIn in range(xShapeIn):\n",
      "                xLeft = xIn - 1\n",
      "                if xIn == 0:\n",
      "                    xLeft = -1\n",
      "                xRight = xIn+1\n",
      "                if xIn == xShapeIn-1:\n",
      "                    xRight = -1\n",
      "                xOut = <int> xIn / fact\n",
      "                \n",
      "                localValue = data[yIn, xIn]\n",
      "                if localValue == _NDV:\n",
      "                    continue\n",
      "                # Max and Min\n",
      "                if localValue > outputMaxArr[yOut, xOut]:\n",
      "                    outputMaxArr[yOut, xOut] = localValue\n",
      "                if localValue < outputMinArr[yOut, xOut]:\n",
      "                    outputMinArr[yOut, xOut] = localValue\n",
      "                # Sum and Count\n",
      "                outputSumArr[yOut, xOut] += localValue\n",
      "                outputCountArr[yOut, xOut] += 1\n",
      "                if not minMaxRangeSumOnly:\n",
      "                    # Running mean and SD\n",
      "                    if outputCountArr[yOut, xOut] == 1:\n",
      "                        _oldMeanArr[yOut, xOut] = localValue\n",
      "                        outputMeanArr[yOut, xOut] = localValue\n",
      "                        _oldSDArr[yOut, xOut] = 0\n",
      "                        outputSDArr[yOut, xOut] = 0\n",
      "                    else:\n",
      "                        outputMeanArr[yOut, xOut] = (_oldMeanArr[yOut, xOut] + \n",
      "                                                     ((localValue - _oldMeanArr[yOut, xOut]) / \n",
      "                                                          outputCountArr[yOut, xOut]))\n",
      "                        outputSDArr[yOut, xOut] = (_oldSDArr[yOut, xOut] +\n",
      "                                                   ((localValue - _oldMeanArr[yOut, xOut]) *\n",
      "                                                    (localValue - outputMeanArr[yOut, xOut])\n",
      "                                                    ))\n",
      "                        _oldMeanArr[yOut, xOut] = outputMeanArr[yOut, xOut]\n",
      "                        _oldSDArr[yOut, xOut] = outputSDArr[yOut, xOut]\n",
      "\n",
      "    for yOut in range(yShapeOut): # not bothering to parallelise this, there are frac**2 fewer cells than before\n",
      "        xOut = -1\n",
      "        for xOut in range(xShapeOut):\n",
      "            if outputCountArr[yOut, xOut] == 0:\n",
      "                outputMinArr[yOut, xOut] = _NDV\n",
      "                outputMaxArr[yOut, xOut] = _NDV\n",
      "                outputRangeArr[yOut, xOut] = _NDV\n",
      "                outputSumArr[yOut, xOut] = _NDV\n",
      "                if not minMaxRangeSumOnly:\n",
      "                    outputMeanArr[yOut, xOut] = _NDV\n",
      "                #continue\n",
      "            else:\n",
      "                # min, max, sum, count are already set\n",
      "                outputRangeArr[yOut, xOut] = outputMaxArr[yOut, xOut] - outputMinArr[yOut, xOut]\n",
      "                if not minMaxRangeSumOnly:\n",
      "                    variance = outputSDArr[yOut, xOut] / outputCountArr[yOut, xOut]\n",
      "                    outputSDArr[yOut, xOut] = sqrt(variance)\n",
      "                    # re-calculate the mean using simple sum/n as the running mean method is more \n",
      "                    # likely to have accumulated (slight) fp errors (in practice they seem to match \n",
      "                    # to around 1e-6 but this will depend on the size of the values)\n",
      "                    outputMeanArr[yOut, xOut] = outputSumArr[yOut, xOut] / outputCountArr[yOut, xOut]\n",
      "    #return np.round(np.asarray(outputArr)).astype(np.uint8)\n",
      "    if not minMaxRangeSumOnly:\n",
      "        return ( # count, max, mean, min, range, sum\n",
      "            np.asarray(outputCountArr),\n",
      "            np.asarray(outputMaxArr),\n",
      "            np.asarray(outputMeanArr).astype(np.float32),\n",
      "            np.asarray(outputMinArr),\n",
      "            np.asarray(outputRangeArr),\n",
      "            np.asarray(outputSumArr),\n",
      "            np.asarray(outputSDArr).astype(np.float32),\n",
      "        )\n",
      "    else:\n",
      "        return (\n",
      "            np.asarray(outputCountArr),\n",
      "            np.asarray(outputMaxArr),\n",
      "            None, #np.asarray(outputMeanArr).astype(np.float32),\n",
      "            np.asarray(outputMinArr),\n",
      "            np.asarray(outputRangeArr),\n",
      "            np.asarray(outputSumArr),\n",
      "            None # np.asarray(outputSDArr).astype(np.float32),\n",
      "        )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --compile-args=/openmp --link-args=/openmp --force\n",
      "cimport cython\n",
      "import numpy as np\n",
      "cimport openmp\n",
      "from cython.parallel import parallel, prange\n",
      "\n",
      "@cython.boundscheck(False)\n",
      "@cython.cdivision(True)\n",
      "@cython.wraparound(False)\n",
      "# aggregates a grid by a specified factor (e.g. 10 to aggegate 500m to 5km data),\n",
      "# producing for each class specified in the input data a grid at the output \n",
      "# resolution for each of fraction and like adjacency.\n",
      "# Like adjacencies are calculated using double-count method whereas Dan's IDL\n",
      "# code used single-count method, so results are slightly different.\n",
      "# Designed for use with MCD12Q1 IBGP landcover data, a couple of classes are hardcoded\n",
      "# to suit this, but they could easily be modified.\n",
      "cpdef aggregateStats(unsigned char[:,::1] landCover, int fact, int nCategories, float fltNDV = -9999):\n",
      "''' Aggregates a categorical raster grid by a specified factor (e.g. 10 to aggegate 500m to 5km data)\n",
      " \n",
      " Returns a tuple containing two three dimensional grids and one two dimensional grid \n",
      " at the aggregated resolution, each representing a different summary of the source \n",
      " pixels covered by each output pixel, namely:\n",
      "    (\n",
      "      Fraction (3D), \n",
      "      Like-Adjacency (3D), \n",
      "      Majority (2D)\n",
      "    )\n",
      " The fraction and like adjacency outputs have one image (in the z dimension) for each category\n",
      " (value) of the input raster. It's assumed that the input has values from zero and the mapping \n",
      " is therefore between the input value and the output position, i.e. an input pixel of value 4\n",
      " will contribute to the 4th grid in the output stack. This is suitable for use with IGBP \n",
      " landcover data.\n",
      " \n",
      " The input grid must (in this implementation) have dimensions that are \n",
      " exact multiples of aggregation factor.\n",
      "'''    \n",
      "    cdef:\n",
      "        Py_ssize_t xShapeIn, yShapeIn, xShapeOut, yShapeOut\n",
      "        Py_ssize_t xIn, yIn, xOut, yOut, catNum\n",
      "        int yBelow, yAbove, xLeft, xRight\n",
      "        unsigned char localValue\n",
      "        float[:,:,::1] outputFracArr\n",
      "        float[:,:,::1] outputLikeAdjArr\n",
      "        unsigned char [:,::1] outputMajorityArr\n",
      "        float [:,::1] tmpMajorityPropArr\n",
      "        float proportion\n",
      "        \n",
      "    yShapeIn = landCover.shape[0]\n",
      "    xShapeIn = landCover.shape[1]\n",
      "    \n",
      "    assert fact > 0\n",
      "    assert yShapeIn % fact == 0\n",
      "    assert xShapeIn % fact == 0\n",
      "    \n",
      "    # how much of an output cell does each input cell account for\n",
      "    proportion = 1.0 / (fact**2)\n",
      "    \n",
      "    yShapeOut = yShapeIn / fact\n",
      "    xShapeOut = xShapeIn / fact\n",
      "    outputFracArr = np.zeros(shape=(nCategories, yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    outputLikeAdjArr = np.zeros(shape=(nCategories, yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    outputMajorityArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.uint8)\n",
      "    tmpMajorityPropArr = np.zeros(shape=(yShapeOut, xShapeOut), dtype = np.float32)\n",
      "    \n",
      "    with nogil, parallel():\n",
      "        #yOut = -1\n",
      "        #xOut = -1\n",
      "        #localValue = -1\n",
      "        for yIn in prange(yShapeIn):\n",
      "            yAbove = yIn - 1\n",
      "            if yIn == 0:\n",
      "                yAbove = -1\n",
      "            yBelow = yIn+1\n",
      "            if yIn == yShapeIn-1:\n",
      "                yBelow = -1\n",
      "            yOut = <int> yIn / fact\n",
      "            localValue=-1\n",
      "            xOut = -1\n",
      "            for xIn in range(xShapeIn):\n",
      "                xLeft = xIn - 1\n",
      "                if xIn == 0:\n",
      "                    xLeft = -1\n",
      "                xRight = xIn+1\n",
      "                if xIn == xShapeIn-1:\n",
      "                    xRight = -1\n",
      "                xOut = <int> xIn / fact\n",
      "                \n",
      "                # fractional landcover\n",
      "                localValue = landCover[yIn, xIn]\n",
      "                # hardcode a remap from the high values into the next available smallest ones\n",
      "                if localValue == 254:\n",
      "                    localValue = 17\n",
      "                elif localValue == 255:\n",
      "                    localValue = 18\n",
      "                outputFracArr [localValue, yOut,xOut] += proportion\n",
      "                \n",
      "                # like-adjacencies\n",
      "                if yAbove>=0 and landCover[yAbove,xIn] == localValue:\n",
      "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
      "                if xRight>=0 and landCover[yIn,xRight] == localValue:\n",
      "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
      "                if yBelow>=0 and landCover[yBelow,xIn] == localValue:\n",
      "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
      "                if xLeft>=0 and landCover[yIn,xLeft] == localValue:\n",
      "                    outputLikeAdjArr[localValue,yOut,xOut] += 0.25 * proportion\n",
      "\n",
      "    for catNum in range (nCategories):\n",
      "        yOut = -1\n",
      "        xOut = -1\n",
      "        for yOut in range(yShapeOut): # not bothering to parallelise this, there are frac**2 fewer cells than before\n",
      "            for xOut in range(xShapeOut):\n",
      "                # like adjacencies are output as a fraction of the cells that were of a class, that\n",
      "                # have neighbours of the same class\n",
      "                if outputFracArr[catNum, yOut, xOut] > 0:\n",
      "                    outputLikeAdjArr[catNum, yOut, xOut] = (\n",
      "                        outputLikeAdjArr[catNum, yOut, xOut] / outputFracArr[catNum, yOut, xOut])\n",
      "                else:\n",
      "                    outputLikeAdjArr[catNum, yOut, xOut] = fltNDV\n",
      "                    \n",
      "                if outputFracArr[catNum, yOut, xOut] > tmpMajorityPropArr[yOut, xOut]:\n",
      "                    tmpMajorityPropArr[yOut, xOut] = outputFracArr[catNum, yOut, xOut]\n",
      "                    if catNum < 17:\n",
      "                        outputMajorityArr[yOut, xOut] = catNum\n",
      "                    elif catNum == 17:\n",
      "                        outputMajorityArr[yOut, xOut] = 254\n",
      "                    elif catNum == 18:\n",
      "                        outputMajorityArr[yOut, xOut] = 255\n",
      "\n",
      "                # output in percent (so we can use int array = smaller)\n",
      "                # it currently contains proportion of the output cell that is covered \n",
      "                # by input cells of that type, i.e. a value 0-1\n",
      "                # and since we are running with frac=10 so 100 inputs to each output, \n",
      "                # there can only be a whole percentage value\n",
      "                outputFracArr[catNum,yOut,xOut] *=100\n",
      "                # C round function won't import into cython on my machine for some reason so\n",
      "                # add 0.5 so that truncating downwards has the same effect\n",
      "                outputFracArr[catNum,yOut,xOut]+=0.5\n",
      "                \n",
      "    #return np.round(np.asarray(outputArr)).astype(np.uint8)\n",
      "    return (\n",
      "        np.asarray(outputFracArr).astype(np.uint8),\n",
      "        np.asarray(outputLikeAdjArr),\n",
      "        np.asarray(outputMajorityArr).astype(np.uint8)\n",
      "    )\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def savecontResult(thing,stat, tag, data,_NDV, outDir, outName = None, decrepit=False):\n",
      "    '''\n",
      "    Save a result from the continuous raster aggregation function, using the MAP filename formats\n",
      "    '''\n",
      "    if data.dtype==np.float32 or data.dtype==np.float64:\n",
      "        gdType = gdal.GDT_Float32\n",
      "    elif data.dtype == np.int8 or data.dtype == np.uint8 or data.dtype == np.byte:\n",
      "        gdType = gdal.GDT_Byte\n",
      "    else:\n",
      "        gdType = gdal.GDT_Int32\n",
      "    \n",
      "    outDrv = gdal.GetDriverByName('GTiff')\n",
      "    if outName is None:\n",
      "        outNameTemplate = r'{0!s}\\{1!s}_5km_{2!s}{3!s}.tif'\n",
      "        outRasterName = outNameTemplate.format(outDir, thing, stat, tag)\n",
      "    else:\n",
      "        outRasterName = os.path.join(outDir, outName)\n",
      "        outRasterName = outRasterName + '.tif'\n",
      "    cOpts = [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"]\n",
      "    if decrepit:\n",
      "        cOpts = []\n",
      "    outRaster = outDrv.Create(outRasterName,data.shape[1], data.shape[0],1,gdType,\n",
      "                              cOpts)\n",
      "    outRaster.SetGeoTransform(outputGT)\n",
      "    outRaster.SetProjection(inputProj)\n",
      "    outBand = outRaster.GetRasterBand(1)\n",
      "    if _NDV:\n",
      "        outBand.SetNoDataValue(_NDV)\n",
      "    outBand.WriteArray(data)\n",
      "    outBand.FlushCache()\n",
      "    del outBand\n",
      "    outRaster = None\n",
      "\n",
      "resStructure = ('Count','Max','Mean','Min','Range','Sum','SD')\n",
      "\n",
      "\n",
      "# To enforce alignment with the mastergrids run the following on each file:\n",
      "# gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Code to run aggregation functions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Define aggregation factor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aggFactor = 5\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outDir = r'C:\\temp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example: run for one continuous dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataPath = r'C:\\Users\\zool1301\\Documents\\Other_Data\\Ferranti_Elev_15Sec\\ferranti15sec_hillshade_Illum360_scale.tif'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = gdal.Open(dataPath)\n",
      "bnd = ds.GetRasterBand(1)\n",
      "_NDV = bnd.GetNoDataValue()\n",
      "inputGT = ds.GetGeoTransform()\n",
      "inputProj = ds.GetProjection()\n",
      "outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outputGT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#xLims = (21840*2,33040*2) # for 1km data\n",
      "#yLims = (9660*2,20560*2) # for 1km data\n",
      "#testArea = bnd.ReadAsArray(xLims[0],yLims[0],xLims[1]-xLims[0],yLims[1]-yLims[0])\n",
      "allData = bnd.ReadAsArray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allData[np.isnan(allData)] = _NDV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Data shape must be a clean muliple of aggregation factor, here we just fudge by cutting the end off"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allData = allData[0:-1, 0:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "outputGT2 = (-180.0, 0.008333333333333, 0.0, 90.0, 0.0, -0.008333333333333)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If we are short of memory do we need mean and sd? (if so we'll have to tile: not yet implemented)\n",
      "SkipMeanAndSD = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Run the calculations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = aggregateContinuous(allData.astype(np.float32), aggFactor, _NDV, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Save all as compressed or uncompressed format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resStructure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Uncompressed\n",
      "for i in range(len(resStructure)):\n",
      "    stat = resStructure[i]\n",
      "    savecontResult(thing,stat,'',res[i],_NDV, outDir, True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Or compressed\n",
      "for i in range(len(resStructure)):\n",
      "    stat = resStructure[i]\n",
      "    savecontResult(thing,stat,'_LZW',res[i],_NDV, outDir, False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Or save manually if we've skipped mean / sd\n",
      "savecontResult('HS360Deg_1k','Count','',res[0],_NDV, outDir, False)\n",
      "savecontResult('HS360Deg_1k','Max','',res[1],_NDV, outDir, False)\n",
      "savecontResult('HS360Deg_1k','Min','',res[3],_NDV, outDir, False)\n",
      "savecontResult('HS360Deg_1k','Range','',res[4],_NDV, outDir, False)\n",
      "savecontResult('HS360Deg_1k','Sum','',res[5],_NDV, outDir, False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example: run for multiple continuous datasets with different names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataPaths = {\n",
      "'EVI_Mean': r'G:\\NewStats\\MG_Aligned\\EVI_Mean_From_Monthly.tif',\n",
      "'LST_Day_Mean': r'G:\\NewStats\\MG_Aligned\\LST_Day_Mean_From_Monthly.tif',\n",
      "'LST_Night_Mean': r'G:\\NewStats\\MG_Aligned\\LST_Night_Mean_From_Monthly.tif',\n",
      "'TCW_Mean': r'G:\\NewStats\\MG_Aligned\\TCW_Mean_From_Monthly.tif',\n",
      "'TCB_Mean': r'G:\\NewStats\\MG_Aligned\\TCB_Mean_From_Monthly.tif',\n",
      "\n",
      "'EVI_SD': r'G:\\NewStats\\MG_Aligned\\EVI_SD_From_Daily.tif',\n",
      "'LST_Day_SD': r'G:\\NewStats\\MG_Aligned\\LST_Day_SD_From_Daily.tif',\n",
      "'LST_Night_SD': r'G:\\NewStats\\MG_Aligned\\LST_Night_SD_From_Daily.tif',\n",
      "'TCW_SD': r'G:\\NewStats\\MG_Aligned\\TCW_SD_From_Daily.tif',\n",
      "'TCB_SD': r'G:\\NewStats\\MG_Aligned\\TCB_SD_From_Daily.tif',}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outDir = r'G:\\SynopticData\\MG_Aligned\\5km\\tmp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for thing in dataPaths:\n",
      "    ds = gdal.Open(dataPaths[thing])\n",
      "    bnd = ds.GetRasterBand(1)\n",
      "    _NDV = bnd.GetNoDataValue()\n",
      "    inputGT = ds.GetGeoTransform()\n",
      "    inputProj = ds.GetProjection()\n",
      "    outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)\n",
      "    print ds.GetDescription()\n",
      "    allData = bnd.ReadAsArray()\n",
      "    allData[np.isnan(allData)] = _NDV\n",
      "    res = aggregateContinuous(allData, aggFactor, _NDV)\n",
      "    for i in range (len(resStructure)):\n",
      "        stat = resStructure[i]\n",
      "        savecontResult(thing,stat,'',res[i],_NDV, outDir, None, True)\n",
      "        savecontResult(thing,stat,'_LZW',res[i],_NDV, outDir, None, False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example: run for multiple continuous datasets in a series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for example some output monthly data cubes at 1km\n",
      "dataPaths = glob.glob(r'G:\\Extra\\Output\\Aggregated\\1km\\TCW*.tif')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = '.'.join(os.path.basename(dataPaths[0]).split(os.path.extsep)[:-1])\n",
      "fn = fn.replace('.1km.Data', '.5km.Mean')\n",
      "fn = fn.replace('1km', '5km')\n",
      "fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outDir = r'G:\\Extra\\Output\\Aggregated\\5km'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Here we are saving only the mean grid from the aggregation stats, which is all that's kept for the 5km cubes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for filename1k in dataPaths:\n",
      "    ds = gdal.Open(filename1k)\n",
      "    bnd = ds.GetRasterBand(1)\n",
      "    _NDV = bnd.GetNoDataValue()\n",
      "    \n",
      "    inputGT = ds.GetGeoTransform()\n",
      "    inputProj = ds.GetProjection()\n",
      "    outputGT = (inputGT[0], inputGT[1]*aggFactor, 0.0, inputGT[3], 0.0, inputGT[5] * aggFactor)\n",
      "    print ds.GetDescription()\n",
      "    allData = bnd.ReadAsArray()\n",
      "    \n",
      "    dTypeIn = allData.dtype\n",
      "    if dTypeIn != np.float32:\n",
      "        allData = allData.astype(np.float32)\n",
      "        dTypeChanged = True\n",
      "    else:\n",
      "        dTypeChanged = False\n",
      "    \n",
      "    if _NDV:\n",
      "        allData[np.isnan(allData)] = _NDV\n",
      "        resMean = aggregateContinuous(allData, aggFactor, _NDV)[2]\n",
      "    else:\n",
      "        resMean = aggregateContinuous(allData, aggFactor)[2]\n",
      "    if dTypeChanged:\n",
      "        resMean = resMean.astype(dTypeIn)\n",
      "    \n",
      "    outFNBase = os.path.extsep.join(os.path.basename(filename1k).split(os.path.extsep)[:-1])\n",
      "    outFNBase = outFNBase.replace('.1km.Data', '.5km.Mean')\n",
      "    outFNBase = outFNBase.replace('1km', '5km')\n",
      "    savecontResult('', '', '', resMean, _NDV, outDir, outFNBase, False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example: run for a single categorical dataset"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Provide category numbers (raster values) and names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The values that the input raster has, which should start from zero\n",
      "ibgpCats = {\n",
      "    0:'Water',\n",
      "    1:'Evergreen_Needleleaf_Forest',\n",
      "    2:'Evergreen_Broadleaf_Forest',\n",
      "    3:'Deciduous_Needleleaf_Forest',\n",
      "    4:'Deciduous_Broadleaf_Forest',\n",
      "    5:'Mixed_Forest',\n",
      "    6:'Closed_Shrublands',\n",
      "    7:'Open_Shrublands',\n",
      "    8:'Woody_Savannas',\n",
      "    9:'Savannas',\n",
      "    10:'Grasslands',\n",
      "    11:'Permanent_Wetlands',\n",
      "    12:'Croplands',\n",
      "    13:'Urban_And_Built_Up',\n",
      "    14:'Cropland_Natural_Vegetation_Mosaic',\n",
      "    15:'Snow_And_Ice',\n",
      "    16:'Barren_Or_Sparsely_Populated',\n",
      "    17:'Unclassified', # =254 in source data, hardcoded a remap in the cython\n",
      "    18:'No_Data' # =255 in source data\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(ibgpCats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nCats = len(ibgpCats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Run the calculations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%timeit\n",
      "# global calculation takes approx 16 seconds\n",
      "res = aggregateStats(allData,10,len(ibgpCats))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Write categorical results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write the results to individual (one per class) tiff files\n",
      "outDrv = gdal.GetDriverByName('GTiff')\n",
      "outNameTemplate = r'G:\\MCD12Q1\\Proportional\\5km\\{0!s}_{1!s}_5km_{2!s}.tif'\n",
      "for i in range(0,len(ibgpCats)):\n",
      "    className = ibgpCats[i]\n",
      "    outRasterName = outNameTemplate.format(i,className,\"Percentage\")\n",
      "    outRaster = outDrv.Create(outRasterName,res[0].shape[2], res[0].shape[1],1,gdal.GDT_Byte,\n",
      "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "    outRaster.SetGeoTransform(outputGT)\n",
      "    outRaster.SetProjection(inputProj)\n",
      "    outBand = outRaster.GetRasterBand(1)\n",
      "    outBand.WriteArray(res[0][i])\n",
      "    outBand.FlushCache()\n",
      "    del outBand\n",
      "    outRasterName = outNameTemplate.format(i,className,\"LikeAdjacencies\")\n",
      "    outRaster = outDrv.Create(outRasterName,res[1].shape[2], res[1].shape[1],1,gdal.GDT_Float32,\n",
      "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "    outRaster.SetGeoTransform(outputGT)\n",
      "    outRaster.SetProjection(inputProj)\n",
      "    outBand = outRaster.GetRasterBand(1)\n",
      "    outBand.WriteArray(res[1][i])\n",
      "    outBand.FlushCache()\n",
      "    del outBand\n",
      "    outRaster = None\n",
      "outRasterName = outNameTemplate.format(\"Overall\", \"Class\", \"Majority\")\n",
      "outRaster = outDrv.Create(outRasterName,res[2].shape[1], res[2].shape[0],\n",
      "                          1,gdal.GDT_Byte,\n",
      "                          [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\n",
      "                           \"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "outRaster.SetGeoTransform(outputGT)\n",
      "outRaster.SetProjection(inputProj)\n",
      "outBand = outRaster.GetRasterBand(1)\n",
      "outBand.WriteArray(res[2])\n",
      "outBand.FlushCache()\n",
      "del outBand\n",
      "outRaster = None\n",
      "# To enforce alignment with the mastergrids run the following on each file:\n",
      "# gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example: run for multiple categorical datasets in a series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataPaths = glob.glob(r'G:\\MCD12Q1\\500m\\*.tif')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = os.path.basename(dataPaths[1]).split(os.path.extsep)[0]\n",
      "fn = fn.replace('_1km_Data', '.5km.Mean')\n",
      "fn = fn.replace('_1km_FilledProportion', '.5km.FilledProportion')\n",
      "fn = fn.replace('Night_', 'Night.')\n",
      "fn = fn.replace('-', '.')\n",
      "fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outDir = r'G:\\MCD12Q1\\5km'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write the results to individual (one per class) tiff files\n",
      "for filename500m in dataPaths:\n",
      "    inFN = os.path.basename(filename500m).split(os.path.extsep)[0]\n",
      "    yr = inFN[1:5]\n",
      "    outDrv = gdal.GetDriverByName('GTiff')\n",
      "    \n",
      "    outNameTemplate = r'{0!s}\\{1!s}\\{2!s}.{3!s}_{4!s}.5km.{5!s}.tif'\n",
      "    \n",
      "    likeAdjNDV = -9999\n",
      "    with rasterio.open(filename500m) as src:\n",
      "        allData = src.read_band(1, masked=False)\n",
      "    res = aggregateStats(allData,10,len(ibgpCats), likeAdjNDV)\n",
      "    \n",
      "    for i in range(0,len(ibgpCats)):\n",
      "        className = ibgpCats[i]\n",
      "        outRasterName = outNameTemplate.format(\n",
      "            outDir, \n",
      "            \"Proportional\", \n",
      "            yr,\n",
      "            \"Class\"+str(i).zfill(2), \n",
      "            className, \n",
      "            \"Percentage\"\n",
      "        )\n",
      "        outRaster = outDrv.Create(outRasterName,res[0].shape[2], res[0].shape[1],1,gdal.GDT_Byte,\n",
      "                                  [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "        outRaster.SetGeoTransform(outputGT)\n",
      "        outRaster.SetProjection(inputProj)\n",
      "        outBand = outRaster.GetRasterBand(1)\n",
      "        outBand.WriteArray(res[0][i])\n",
      "        outBand.FlushCache()\n",
      "        del outBand\n",
      "        \n",
      "        #outRasterName = outNameTemplate.format(outDir, i, className, \"LikeAdjacencies\")\n",
      "        outRasterName = outNameTemplate.format(\n",
      "            outDir, \n",
      "            \"LikeAdjacencies\", \n",
      "            yr,\n",
      "            \"Class\"+str(i).zfill(2), \n",
      "            className, \n",
      "            \"LikeAdjacencies\"\n",
      "        )\n",
      "        outRaster = outDrv.Create(outRasterName,res[1].shape[2], res[1].shape[1],1,gdal.GDT_Float32,\n",
      "                                  [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "        outRaster.SetGeoTransform(outputGT)\n",
      "        outRaster.SetProjection(inputProj)\n",
      "        outBand = outRaster.GetRasterBand(1)\n",
      "        outBand.SetNoDataValue(likeAdjNDV)\n",
      "        outBand.WriteArray(res[1][i])\n",
      "        outBand.FlushCache()\n",
      "        del outBand\n",
      "        outRaster = None\n",
      "        \n",
      "    #outRasterName = outNameTemplate.format(\"Overall\", \"Class\", \"Majority\")\n",
      "    outRasterName = outNameTemplate.format(\n",
      "            outDir, \n",
      "            \"Majority\", \n",
      "            yr,\n",
      "            \"Overall\", \n",
      "            \"Class\", \n",
      "            \"Majority\"\n",
      "        )\n",
      "    outRaster = outDrv.Create(outRasterName,res[2].shape[1], res[2].shape[0],\n",
      "                              1,gdal.GDT_Byte,\n",
      "                              [\"TILED=YES\",\"SPARSE_OK=TRUE\",\"BIGTIFF=YES\",\n",
      "                               \"COMPRESS=LZW\",\"PREDICTOR=2\"])\n",
      "    outRaster.SetGeoTransform(outputGT)\n",
      "    outRaster.SetProjection(inputProj)\n",
      "    outBand = outRaster.GetRasterBand(1)\n",
      "    outBand.WriteArray(res[2])\n",
      "    outBand.FlushCache()\n",
      "    del outBand\n",
      "    outRaster = None\n",
      "    # To enforce alignment with the mastergrids run the following on each file:\n",
      "    # gdal_edit %filename.tif% -a_ullr -180 89.99994 179.9998560 -89.999988"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}