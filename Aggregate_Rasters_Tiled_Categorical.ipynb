{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for aggregating (resampling down) categorical rasters, for example to convert the MODIS 30 arcsecond (~1km) grids into 2.5 arcminute (~5km) grids. (Code for aggregating continuous rasters is provided in another notebook/module).\n",
    "\n",
    "Categorical rasters can be aggregated to produce one class proportion and one like adjacency grid for each of the input values, and a single majority grid. This assumes that the input grids have a small-ish number of unique values, and are in unsigned 8 bit integer format (it was written for the MCD12Q1 BRDF landcover data).\n",
    "\n",
    "The actual aggregation code is in the Cython_Raster_Funcs/RasterAggregator_Categorical.pxd file. This is, or needs to be, translated to C using the Cython translation / compilation tools. This notebook provides demonstrations of how to run the cythonized code.\n",
    "\n",
    "The code has been written to read input rasters of theoreticlly unlimited size, which are read in tiles to build up the output coarser / smaller grids. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import / build the aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the cython module. If the c code has not already been generated by cython then you\n",
    "# first need to change to the directory containing the .pxd file and run \n",
    "# python setup.py build_ext --inplace\n",
    "\n",
    "from Cython_Raster_Funcs.RasterAggregator_Categorical import RasterAggregator_Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import other common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from General_Raster_Funcs.GeotransformCalcs import calcAggregatedProperties\n",
    "from General_Raster_Funcs.RasterTiling import getTiles\n",
    "from General_Raster_Funcs.TiffManagement import SaveLZWTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run the aggregation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function demonstrates splitting the incoming file(s) into tiles if necessary, loading the data, running the cython-based aggregation function, and saving the results. It's based on configuring a few global variables in the notebook just for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categoricalAggregationRunner(dataPaths, categories):\n",
    "    '''Run the aggregation code for each file specifed in dataPaths\n",
    "    \n",
    "    which should be a list of tiff files.\n",
    "    \n",
    "    The global notebook variables outDir, method, minMaxRangeSumOnly, itemsToSave, tileSize, \n",
    "    and (aggregationFactor OR resolution OR requiredXSize and requiredYSize)\n",
    "    should be set first, along with the fnGetter function for producing output filenames.\n",
    "    '''\n",
    "    for f in dataPaths:\n",
    "        print f\n",
    "        ds = gdal.Open(f)\n",
    "        b = ds.GetRasterBand(1)\n",
    "        catNdv = b.GetNoDataValue()\n",
    "        if catNdv is None:\n",
    "            # force for water extent:\n",
    "            catNdv = 255\n",
    "            print \"no ndv\"\n",
    "        else:\n",
    "            catNdv = int(catNdv)\n",
    "            print \"incoming ndv is \"+str(catNdv)\n",
    "        fltNdv = -9999\n",
    "        inputGT = ds.GetGeoTransform()\n",
    "        inputProj = ds.GetProjection()\n",
    "        \n",
    "        if isinstance(categories, int):\n",
    "            assert categories <= 256\n",
    "            assert categories < 256\n",
    "            assert categories >= 0\n",
    "            nCategories = categories\n",
    "        else:\n",
    "            assert len(categories) <= 256\n",
    "            assert max(categories) < 256\n",
    "            assert min(categories) >= 0\n",
    "\n",
    "            nCategories = len(categories)\n",
    "\n",
    "        nBytesRequired = ds.RasterXSize * ds.RasterYSize * 1 * nCategories\n",
    "\n",
    "        outGT, outShape = calcAggregatedProperties(method, (ds.RasterYSize, ds.RasterXSize), \n",
    "                                                   inputGT, aggregationFactor or None, \n",
    "                                                   (requiredYSize, requiredXSize), \n",
    "                                                   resolution or None)\n",
    "        outYSize, outXSize = outShape    \n",
    "        tiles = getTiles(ds.RasterXSize, ds.RasterYSize, tileSize)\n",
    "        \n",
    "        aggregator = RasterAggregator_Categorical(ds.RasterXSize, ds.RasterYSize, \n",
    "                                            outXSize, outYSize,\n",
    "                                            nCategories,\n",
    "                                            fltNdv,\n",
    "                                            catNdv)\n",
    "        print \"Running {0!s} tiles\".format(len(tiles)),\n",
    "        for tile in tiles:\n",
    "            print \".\",\n",
    "            xoff = tile[0][0]\n",
    "            yoff = tile[1][0]\n",
    "            xsize = tile[0][1] - xoff\n",
    "            ysize = tile[1][1] - yoff\n",
    "            inArr = b.ReadAsArray(xoff, yoff, xsize, ysize).astype(np.uint8)\n",
    "            # if required, do a cheeky reclass along the way\n",
    "            # e.g. to categorise into binary data before using that as the aggregation basis\n",
    "            if reclassify is not None:\n",
    "                inArr = reclassify(inArr)\n",
    "            aggregator.addTile(inArr, xoff, yoff)\n",
    "        r = aggregator.GetResults()\n",
    "        itemstosave = ['fractions','likeadjacencies','majority']\n",
    "        if r is None:\n",
    "            raise Exception(\"An error occurred running the aggregation code\")\n",
    "        print r['valuemap']\n",
    "        for i in range (0, nCategories):\n",
    "            outValue = r['valuemap'][i]\n",
    "            outRasterName = fnGetter(os.path.basename(f), outValue, \"Percentage\")\n",
    "            SaveLZWTiff(r['fractions'][i], fltNdv, outGT, inputProj, outDir, outRasterName)\n",
    "            outRasterName = fnGetter(os.path.basename(f), outValue, \"LikeAdjacency\")\n",
    "            SaveLZWTiff(r['likeadjacencies'][i], fltNdv, outGT, inputProj, outDir, outRasterName)\n",
    "            \n",
    "        outRasterName = fnGetter(os.path.basename(f), \"Overall\", \"Majority\")\n",
    "        SaveLZWTiff(r['majority'], catNdv, outGT, inputProj, outDir, outRasterName)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the globals to configure the data we want to use in the aggregation runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All of the items in this cell are required by the continuousAggregationRunner function:\n",
    "\n",
    "# 1. Specify the method by which the aggregation will be described\n",
    "method = \"resolution\" # \"factor\" or \"size\" or \"resolution\"\n",
    "\n",
    "# and whichever one of these is relevant\n",
    "# if method = 'factor' then\n",
    "aggregationFactor = None #5\n",
    "# OR if method = 'size' then\n",
    "requiredXSize = 8640 \n",
    "requiredYSize = 4320\n",
    "# OR if method = 'resolution' then specify a numeric cellsize or \n",
    "# a string from '1km', '5km', '10km'\n",
    "resolution = '5km' #0.25\n",
    "\n",
    "# 4. specify the folder where the outputs should be saved\n",
    "#outDir = r\"C:\\temp\\testagg\\categorical\"\n",
    "outDir = r\"C:\\Temp\\dataprep\\water\\seasonality\"\n",
    "# 5. specify a function called fnGetter, to get the output filename \n",
    "# (excluding folder), given an input filename and statistic type \n",
    "# (as in the itemstosave above)\n",
    "outNameTemplate = r'{0!s}.{1!s}.{2!s}.tif'\n",
    "fnGetter = lambda fn, num, tag:(outNameTemplate.format(\n",
    "    os.path.splitext(os.path.basename(fn))[0],\n",
    "    \"Class_\" + str(num),\n",
    "    tag))\n",
    "likeAdjNDV = -9999\n",
    "\n",
    "# 6. specify a maximum tilesize for data to read in\n",
    "# for the global 1km grids use 43200 to run untiled\n",
    "tileSize = 43200\n",
    "\n",
    "# 7. optionally specify a reclassify function to pre-prepare the incoming data into categories\n",
    "reclassify = None\n",
    "\n",
    "#def reclassify(arr):\n",
    "#    import numexpr as ne\n",
    "#    a = arr\n",
    "#    expr = 'where (a < 80, 0, where (a== 255, 255, 1))'\n",
    "#    return ne.evaluate(expr).astype(np.uint8)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the paths of the data file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# provide them as a list even if only 1\n",
    "#dataPaths = [r'G:\\MCD12Q1\\500m\\A2013001_MCD12Q1.tif']\n",
    "dataPaths = [r'E:\\Temp\\water\\seasonality.vrt']\n",
    "#dataPaths = [r'C:\\Users\\zool1301.NDPH\\Documents\\Other_Data\\GUF\\GUF28\\GUF28\\00116666665417_N\\0011_N_files_aligned.tif']\n",
    "#dataPaths = glob.glob(r'C:\\Users\\zool1301.NDPH\\Documents\\Other_Data\\GUF\\GUF28\\GUF28\\**\\*files_aligned.tif')\n",
    "# generate with glob pattern if there's lots e.g. \n",
    "# dataPaths = glob.glob(r'G:\\MCD12Q1\\500m\\A2013*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to provide a list of category values or just the number of categories that there are. This should be a small-ish number, depending on the size of the output grids requested: there will be one like-adjacency and one fraction grid to fit into memory for each category. In any case there must be <= 255 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categoricalAggregationRunner(dataPaths, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fnGetter function could be more sophisticated to name the outputs more descriptively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The values that the input raster has, which should start from zero\n",
    "ibgpCats = {\n",
    "    0:'Water',\n",
    "    1:'Evergreen_Needleleaf_Forest',\n",
    "    2:'Evergreen_Broadleaf_Forest',\n",
    "    3:'Deciduous_Needleleaf_Forest',\n",
    "    4:'Deciduous_Broadleaf_Forest',\n",
    "    5:'Mixed_Forest',\n",
    "    6:'Closed_Shrublands',\n",
    "    7:'Open_Shrublands',\n",
    "    8:'Woody_Savannas',\n",
    "    9:'Savannas',\n",
    "    10:'Grasslands',\n",
    "    11:'Permanent_Wetlands',\n",
    "    12:'Croplands',\n",
    "    13:'Urban_And_Built_Up',\n",
    "    14:'Cropland_Natural_Vegetation_Mosaic',\n",
    "    15:'Snow_And_Ice',\n",
    "    16:'Barren_Or_Sparsely_Populated',\n",
    "    17:'Unclassified', # =254 in source data, hardcoded a remap in the cython\n",
    "    18:'No_Data' # =255 in source data\n",
    "}\n",
    "\n",
    "fnGetter = lambda fn, num, tag:(outNameTemplate.format(\n",
    "    os.path.splitext(os.path.basename(fn))[0],\n",
    "    \"Class_\" + str(num) + \"_\" + ibgpCats[num] + \"_\",\n",
    "    tag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
